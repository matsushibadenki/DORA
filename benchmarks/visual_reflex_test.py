# benchmarks/visual_reflex_test.py
# Title: DORA Visual Reflex Test
# Description: 
#   åˆæˆç”»åƒã‚’ç”¨ã„ã¦è¦–è¦šé‡Žã®åå¿œã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚
#   - èµ¤ã„ç”»åƒ (Red) -> ç‚Žã‚’é€£æƒ³ -> å±é™ºåˆ¤å®š -> é€ƒèµ° (ESCAPE)
#   - é’ã„ç”»åƒ (Blue) -> ç©ºã‚’é€£æƒ³ -> å®‰å…¨åˆ¤å®š -> é™è¦³ (IDLE)

import sys
import os
import logging
from PIL import Image
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(str(Path(__file__).resolve().parents[1]))

from app.containers import AppContainer
from snn_research.cognitive_architecture.visual_cortex import VisualCortex
from snn_research.cognitive_architecture.motor_cortex import MotorCortex

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def create_dummy_image(color, size=(224, 224)):
    """å˜è‰²ã®ç”»åƒã‚’ç”Ÿæˆã™ã‚‹"""
    return Image.new('RGB', size, color=color)

def run_visual_test():
    print("\n" + "="*60)
    print("ðŸ‘ï¸ DORA Visual Reflex Test (CLIP Sensation)")
    print("="*60 + "\n")

    # Initialize
    container = AppContainer()
    config_path = Path("configs/templates/base_config.yaml")
    if config_path.exists():
        container.config.from_yaml(str(config_path))
    
    container.config.training.paradigm.from_value("event_driven")
    container.config.device.from_value("cpu")
    
    os_kernel = container.neuromorphic_os()
    brain = os_kernel.brain
    os_kernel.boot()
    
    # Initialize Cortices
    # åˆå›žãƒ­ãƒ¼ãƒ‰æ™‚ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
    visual_cortex = VisualCortex(brain)
    motor_cortex = MotorCortex(brain, threshold=12.0) # Languageã¨åŒã˜é–¾å€¤
    
    # Test Scenarios
    # CLIPã¯è‰²ã¨æ¦‚å¿µã‚’çµã³ã¤ã‘ã‚‹ã®ãŒå¾—æ„ã§ã™
    scenarios = [
        {"name": "Calm Sky",  "color": (135, 206, 235)}, # Light Blue
        {"name": "Forest",    "color": (34, 139, 34)},   # Green
        {"name": "INFERNO",   "color": (255, 69, 0)},    # Red-Orange (Fire)
        {"name": "Darkness",  "color": (10, 10, 10)}     # Black
    ]
    
    for scene in scenarios:
        print(f"\nðŸ–¼ï¸ Scene: [{scene['name']}]")
        
        # ç”»åƒç”Ÿæˆ
        img = create_dummy_image(scene['color'])
        
        # 1. See (Visual Cortex)
        spikes = visual_cortex.process_image(img)
        
        # 2. Act (Motor Cortex)
        action = motor_cortex.monitor_and_act(spikes)
        
        print(f"   -> Resulting Action: {action}")

    # Cleanup
    os_kernel.shutdown()
    print("\n" + "="*60)
    print("âœ… Visual Test Complete")
    print("="*60)

if __name__ == "__main__":
    run_visual_test()