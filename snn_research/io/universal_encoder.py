# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/io/universal_encoder.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Universal Encoder (Offline Fix)
# ä¿®æ­£å†…å®¹: ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã®è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ã€‚

import torch
import torch.nn as nn
import logging

logger = logging.getLogger(__name__)

# Transformersã‚’ç„¡åŠ¹åŒ–
TRANSFORMERS_AVAILABLE = False

class UniversalEncoder(nn.Module):
    """
    ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ï¼‰ã‚’çµ±ä¸€çš„ãªã‚¹ãƒ‘ã‚¤ã‚¯è¡¨ç¾ã«å¤‰æ›ã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€‚
    (ç¾åœ¨ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰/ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã—ã¦æ©Ÿèƒ½)
    """
    def __init__(self, output_dim: int = 784, device: str = 'cpu'):
        super().__init__()
        self.output_dim = output_dim
        self.device = device
        logger.info("ğŸŒ UniversalEncoder initialized (Offline Mode).")

    def forward(self, x, modality: str = "text"):
        # ãƒ€ãƒŸãƒ¼å®Ÿè£…: ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¹ãƒ‘ã‚¤ã‚¯ã‚’è¿”ã™
        batch_size = 1
        if isinstance(x, torch.Tensor):
            batch_size = x.shape[0]
        
        return torch.rand(batch_size, self.output_dim).to(self.device)