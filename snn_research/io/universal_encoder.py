# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/io/universal_encoder.py
# æ—¥æœ¬èªžã‚¿ã‚¤ãƒˆãƒ«: Universal Encoder (Offline Fix)
# ä¿®æ­£å†…å®¹: ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã®è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ã€‚

import torch
import torch.nn as nn
import logging

logger = logging.getLogger(__name__)

# Transformersã‚’ç„¡åŠ¹åŒ–
TRANSFORMERS_AVAILABLE = False


class UniversalEncoder(nn.Module):
    """
    ãƒžãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ï¼‰ã‚’çµ±ä¸€çš„ãªã‚¹ãƒ‘ã‚¤ã‚¯è¡¨ç¾ã«å¤‰æ›ã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€‚
    (ç¾åœ¨ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰/ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã—ã¦æ©Ÿèƒ½)
    """

    def __init__(self, output_dim: int = 784, device: str = 'cpu', **kwargs):
        super().__init__()
        self.output_dim = output_dim
        self.device = device
        self.kwargs = kwargs  # Store extra args
        self.time_steps = kwargs.get('time_steps', 1)
        logger.info(
            f"ðŸŒ UniversalEncoder initialized (Offline Mode). Args: {kwargs}")

    def forward(self, x, modality: str = "text", **kwargs):
        # ãƒ€ãƒŸãƒ¼å®Ÿè£…: ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¹ãƒ‘ã‚¤ã‚¯ã‚’è¿”ã™
        batch_size = 1
        if isinstance(x, torch.Tensor):
            batch_size = x.shape[0]

        return (torch.rand(batch_size, self.time_steps, self.output_dim) > 0.95).float().to(self.device)

    # Alias for compatibility with Brain v4 and Agents
    encode = forward
    encode_text = forward


# Legacy support / Alias
UniversalSpikeEncoder = UniversalEncoder
