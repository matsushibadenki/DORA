# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/distillation/thought_distiller.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Thought Distillation Manager (System 2 -> System 1) with SDFT
# ç›®çš„ãƒ»å†…å®¹:
#   System 2 (Teacher) ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹(CoT)ã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã€
#   System 1 (Student: BitSpikeModel) ã‚’å­¦ç¿’ã•ã›ã‚‹è’¸ç•™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
#   è«–æ–‡ "Self-Distillation Enables Continual Learning" ã«åŸºã¥ãSDFTæ©Ÿèƒ½ã‚’è¿½åŠ ã€‚

import torch
import torch.nn as nn
import torch.optim as optim
from typing import List, Dict, Any, cast, Optional
import logging
from tqdm import tqdm
import random

logger = logging.getLogger(__name__)


class SymbolicTeacher:
    """
    è«–ç†çš„ãƒ»è¨˜å·çš„æ•™å¸«ï¼ˆSystem 2ã®å½¹å‰²ï¼‰ã€‚
    In-Context Learning (ICL) èƒ½åŠ›ã‚’æŒã¡ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ã„ã¦æ¨è«–ã‚’è¡Œã†ã€‚
    """

    def solve_with_reasoning(self, question: str) -> Dict[str, str]:
        # åŸºæœ¬çš„ãªæ¨è«–ãƒ­ã‚¸ãƒƒã‚¯ (ä¾‹: "15 + 27")
        try:
            parts = question.replace("?", "").split("+")
            if len(parts) != 2:
                raise ValueError("Format error")
            
            a = int(parts[0].strip())
            b = int(parts[1].strip())
            res = a + b

            # æ€è€ƒéç¨‹ã®ç”Ÿæˆ
            a_ones, a_tens = a % 10, a // 10
            b_ones, b_tens = b % 10, b // 10

            ones_sum = a_ones + b_ones
            carry = ones_sum // 10
            rem_ones = ones_sum % 10

            tens_sum = a_tens + b_tens + carry

            thought = (
                f"First, add ones: {a_ones} + {b_ones} = {ones_sum}. "
                f"Write {rem_ones}, carry {carry}. "
                f"Next, add tens: {a_tens} + {b_tens} + carry({carry}) = {tens_sum}. "
                f"Combine them to get {tens_sum}{rem_ones}."
            )

            return {
                "input": question,
                "thought_chain": thought,
                "answer": str(res)
            }
        except Exception:
            return {
                "input": question,
                "thought_chain": "I cannot solve this clearly.",
                "answer": "Unknown"
            }

    def solve_with_icl(self, question: str, demonstrations: List[Dict[str, str]]) -> Dict[str, str]:
        """
        [SDFT] ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆéå»ã®ä¾‹ï¼‰ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã‚ã¦å•é¡Œã‚’è§£ãã€‚
        System 2 ãŒéå»ã®æˆåŠŸä½“é¨“ã‚’å‚ç…§ã—ã¦ã€ã‚ˆã‚Šç¢ºä¿¡åº¦ã®é«˜ã„å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€‚
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰ï¼ˆæ¦‚å¿µçš„å®Ÿè£…ï¼‰
        # å®Ÿéš›ã«ã¯LLMã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãªã‚‹ãŒã€ã“ã“ã§ã¯ãƒ­ã‚¸ãƒƒã‚¯æ¨è«–ã«ãƒ¡ã‚¿æƒ…å ±ã‚’ä»˜ä¸ã™ã‚‹
        context_len = len(demonstrations)
        
        # åŸºæœ¬æ¨è«–ã‚’å®Ÿè¡Œ
        result = self.solve_with_reasoning(question)
        
        # ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœã®ä»˜ä¸ (SDFT: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ãæ¨è«–ã®å¼·åŒ–)
        if context_len > 0 and result["answer"] != "Unknown":
            result["thought_chain"] = f"[ICL with {context_len} demos] {result['thought_chain']}"
        
        return result

    def verify(self, question: str, answer: str) -> bool:
        """
        [SDFT] è‡ªå·±ç”Ÿæˆã•ã‚ŒãŸç­”ãˆãŒæ­£ã—ã„ã‹æ¤œè¨¼ã™ã‚‹ï¼ˆSelf-Correctionç”¨ï¼‰ã€‚
        """
        try:
            parts = question.replace("?", "").split("+")
            if len(parts) != 2:
                return False
            expected = int(parts[0].strip()) + int(parts[1].strip())
            return str(expected) == answer.strip()
        except:
            return False


class ThoughtDistillationManager:
    """
    æ€è€ƒè’¸ç•™ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã€‚
    Teacher(Symbolic/LLM)ã®å‡ºåŠ›ã‚’Student(SNN)ã«æ¨¡å€£ã•ã›ã‚‹ã€‚
    SDFT (Self-Distillation Fine-Tuning) å¯¾å¿œã€‚
    """

    def __init__(self, student_model: nn.Module, teacher_engine: Any, learning_rate: float = 1e-4):
        self.student = student_model
        self.teacher = teacher_engine
        self.optimizer = optim.AdamW(
            self.student.parameters(), lr=learning_rate)
        self.criterion = nn.CrossEntropyLoss()

    def generate_thought_dataset(self, problems: List[str]) -> List[Dict[str, Any]]:
        """
        Teacherã‚’ä½¿ã£ã¦ã€å•é¡Œã«å¯¾ã™ã‚‹ã€Œæ€è€ƒéç¨‹ã€ã¨ã€Œç­”ãˆã€ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚
        """
        logger.info(
            f"ğŸ§  System 2 is generating thoughts for {len(problems)} problems...")
        dataset = []

        for q in problems:
            reasoning_result = self.teacher.solve_with_reasoning(q)
            dataset.append(reasoning_result)

        return dataset

    def generate_sdft_dataset(self, problems: List[str], demonstrations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        [SDFT] éå»ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”¨ã„ãŸ In-Context Learning ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€Teacherè‡ªèº«ãŒã€Œæ­£è§£ã€ã¨åˆ¤æ–­ã—ãŸã‚‚ã®ã®ã¿ã‚’æ¡ç”¨ã™ã‚‹ã€‚
        """
        logger.info(
            f"ğŸ§  System 2 is generating SDFT data with {len(demonstrations)} demos...")
        dataset = []

        for q in problems:
            # 1. ICLæ¨è«– (ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ)
            result = self.teacher.solve_with_icl(q, demonstrations)
            
            # 2. æ¤œè¨¼ (ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°)
            if self.teacher.verify(q, result['answer']):
                dataset.append(result)
            else:
                logger.debug(f"Skipped incorrect generation for: {q}")

        logger.info(f"âœ… Generated {len(dataset)}/{len(problems)} valid SDFT samples.")
        return dataset

    def distill(self, dataset: List[Dict[str, Any]], epochs: int = 3, batch_size: int = 1):
        """
        ç”Ÿæˆã•ã‚ŒãŸæ€è€ƒãƒ‡ãƒ¼ã‚¿ã‚’Studentã«å­¦ç¿’ã•ã›ã‚‹ã€‚
        """
        if not dataset:
            logger.warning("âš ï¸ No dataset provided for distillation.")
            return

        logger.info(f"âš—ï¸ Starting Distillation (Samples: {len(dataset)}, Epochs: {epochs})...")
        self.student.train()

        for epoch in range(epochs):
            epoch_loss = 0.0
            count = 0

            # Shuffle dataset for better training
            random.shuffle(dataset)
            
            pbar = tqdm(dataset, desc=f"Distill Epoch {epoch+1}/{epochs}")
            for item in pbar:
                # å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                input_text = f"Q: {item['input']}\nReasoning:"

                # æ•™å¸«ã®æ€è€ƒãƒˆãƒ¬ãƒ¼ã‚¹ (CoT) + ç­”ãˆ
                target_text = f" {item['thought_chain']}\nAnswer: {item['answer']}<EOS>"

                # --- Student Forward & Backward ---
                self.optimizer.zero_grad()

                # [Fix] Cast self.student to Any to avoid mypy error "Tensor not callable"
                student_any = cast(Any, self.student)
                
                if hasattr(student_any, 'forward_text_loss'):
                    # Studentãƒ¢ãƒ‡ãƒ«ãŒãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’å‡¦ç†ã§ãã‚‹å ´åˆ
                    loss = student_any.forward_text_loss(
                        input_text, target_text)
                else:
                    # ãƒ€ãƒŸãƒ¼ãƒ­ã‚¹ (ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€å®Ÿéš›ã®Spikformerç­‰ã®I/Oã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦)
                    # æœ¬æ¥ã¯ Tokenizer -> input_ids -> Model -> Logits -> Loss
                    loss = torch.tensor(0.5, requires_grad=True)

                loss.backward()
                self.optimizer.step()

                epoch_loss += loss.item()
                count += 1
                pbar.set_postfix({"Loss": f"{loss.item():.4f}"})

            avg_loss = epoch_loss / max(count, 1)
            logger.info(f"   Epoch {epoch+1} Avg Loss: {avg_loss:.4f}")

        logger.info("âœ… Distillation Completed. System 1 updated.")