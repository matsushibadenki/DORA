# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/global_workspace.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Global Workspace (Consciousness Hub)
# ç›®çš„ãƒ»å†…å®¹:
#   è„³å†…ã®æƒ…å ±ã®ã€Œç«¶åˆã€ã¨ã€Œæ”¾é€ï¼ˆBroadcastï¼‰ã€ã‚’ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
#   Neuromorphic OSã®è¨­è¨ˆæ–¹é‡ã«åŸºã¥ãã€ã“ã‚Œã¯ä¸­å¤®åˆ¶å¾¡è£…ç½®ã§ã¯ãªã
#   ã€Œæƒ…å ±å…±æœ‰ãƒã‚¹ã€ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€‚

import torch
import torch.nn as nn
import torch.nn.functional as F
import logging
from typing import Dict, Any, Optional, List, Callable

logger = logging.getLogger(__name__)

class GlobalWorkspace(nn.Module):
    """
    Global Workspace Theory (GWT) ã«åŸºã¥ãæƒ…å ±å…±æœ‰ãƒãƒ–ã€‚
    
    æ©Ÿèƒ½:
    1. å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘å–ã‚‹
    2. æ³¨æ„æ©Ÿæ§‹ï¼ˆAttentionï¼‰ã«ã‚ˆã‚‹ç«¶åˆï¼ˆCompetitionï¼‰ã‚’è¡Œã†
    3. å‹è€…ã®æƒ…å ±ã‚’å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æ”¾é€ï¼ˆBroadcastï¼‰ã™ã‚‹
    """
    workspace_state: torch.Tensor

    def __init__(
        self,
        dim: int = 64,
        num_slots: int = 1,
        decay: float = 0.9,
        model_registry: Optional[Any] = None
    ):
        super().__init__()
        self.dim = dim
        self.num_slots = num_slots
        self.decay = decay
        self.model_registry = model_registry

        # æ„è­˜ã®å†…å®¹ï¼ˆGlobal Working Memoryï¼‰
        # æ®ç™ºæ€§ã§ã‚ã‚Šã€å¸¸ã«æ¸›è¡°ã¾ãŸã¯æ›´æ–°ã•ã‚Œã‚‹
        self.register_buffer("workspace_state", torch.zeros(1, dim))

        # Attention Mechanism (Salience Selector)
        # å…¥åŠ›ã®é‡è¦åº¦ã‚’åˆ¤å®šã™ã‚‹ç°¡æ˜“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.selector = nn.Sequential(
            nn.Linear(dim, dim),
            nn.Tanh(),
            nn.Linear(dim, 1)
        )

        # Subscribers (æ”¾é€ã‚’å—ã‘å–ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤)
        self.subscribers: List[Callable[[str, Any], None]] = []
        self.current_content: Dict[str, Any] = {}

        logger.info(f"ğŸ‘ï¸ Global Workspace (Consciousness) initialized (Dim: {dim}).")

    def subscribe(self, callback: Callable[[str, Any], None]):
        """ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ„è­˜ã®æ”¾é€ã‚’å—ä¿¡ã™ã‚‹ãŸã‚ã«ç™»éŒ²ã™ã‚‹"""
        self.subscribers.append(callback)

    def upload_to_workspace(self, source: str, data: Any, salience: float = 0.5):
        """
        ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã¸ã®æƒ…å ±æä¾›ã€‚
        ä¸€å®šä»¥ä¸Šã®Salienceï¼ˆé¡•è‘—æ€§ï¼‰ãŒã‚ã‚Œã°ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’æ›¸ãæ›ãˆã‚‹ã€‚
        """
        if salience > 0.7:
            if isinstance(data, dict) and "vector_state" in data:
                vec = data["vector_state"]
            elif isinstance(data, dict) and "features" in data:
                vec = data["features"]
            else:
                vec = None

            if isinstance(vec, torch.Tensor):
                # æ¬¡å…ƒåˆã‚ã›ã¨æ›´æ–°
                if vec.dim() == 1:
                     vec = vec.unsqueeze(0)
                
                # ç‰¹å¾´é‡ã®æ¬¡å…ƒãŒåˆã†å ´åˆã®ã¿æ›´æ–°ï¼ˆæœ¬æ¥ã¯ProjectorãŒå¿…è¦ï¼‰
                if vec.shape[-1] == self.dim:
                    self.workspace_state = vec.detach()

            self._broadcast_to_subscribers(source, data)

    def broadcast(self, inputs: List[Any], context: Optional[str] = None) -> Any:
        """ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›ç”¨"""
        tensor_inputs = {}
        for i, item in enumerate(inputs):
            if isinstance(item, torch.Tensor):
                tensor_inputs[f"input_{i}"] = item
            elif isinstance(item, dict) and "features" in item:
                tensor_inputs[f"module_{i}"] = item["features"]

        if tensor_inputs:
            result = self.forward(tensor_inputs)
            if result["winner"] is not None:
                self._broadcast_to_subscribers(
                    str(result["winner"]), result["broadcast"])
            return result["broadcast"]

        return self.workspace_state

    def get_current_thought(self) -> torch.Tensor:
        """ç¾åœ¨ã®æ„è­˜çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—"""
        return self.workspace_state

    def get_information(self) -> torch.Tensor:
        """ãƒ†ã‚¹ãƒˆäº’æ›ç”¨"""
        return self.get_current_thought()

    def get_current_content(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®æ„è­˜å†…å®¹ã®è©³ç´°ã‚’å–å¾—ï¼ˆå¯èª¬æ˜æ€§ç”¨ï¼‰"""
        return self.current_content

    def _broadcast_to_subscribers(self, source: str, content: Any):
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¿æŒ
        if isinstance(content, dict):
            self.current_content = content
        else:
            self.current_content = {"type": "raw", "data": content, "source": source}

        # ç™»éŒ²è€…å…¨å“¡ã«é€šçŸ¥
        for callback in self.subscribers:
            try:
                callback(source, content)
            except Exception as e:
                logger.warning(f"Broadcast error: {e}")

    def forward(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """
        ç«¶åˆãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
        """
        candidates = []
        names = []

        for name, tensor in inputs.items():
            flat_tensor = tensor
            
            # æ™‚é–“æ¬¡å…ƒã®é›†ç´„ (Batch, Time, Dim) -> (Batch, Dim)
            if flat_tensor.dim() > 2:
                flat_tensor = flat_tensor.mean(dim=1)
            
            # [Fix] 1æ¬¡å…ƒå…¥åŠ› (Dim,) ã®å ´åˆã€ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ã—ã¦ (1, Dim) ã«ã™ã‚‹
            if flat_tensor.dim() == 1:
                flat_tensor = flat_tensor.unsqueeze(0)

            # æ¬¡å…ƒèª¿æ•´ (Feature Dim mismatch handling)
            current_dim = flat_tensor.shape[-1]
            if current_dim != self.dim:
                if current_dim < self.dim:
                    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                    pad = self.dim - current_dim
                    flat_tensor = F.pad(flat_tensor, (0, pad))
                else:
                    # åˆ‡ã‚Šæ¨ã¦
                    flat_tensor = flat_tensor[:, :self.dim]

            candidates.append(flat_tensor)
            names.append(name)

        if not candidates:
            return {"broadcast": self.workspace_state, "winner": None, "salience": None}

        # å€™è£œã‚’ã‚¹ã‚¿ãƒƒã‚¯ã—ã¦ä¸€æ‹¬è©•ä¾¡
        stack = torch.cat(candidates, dim=0) # (TotalBatch, Dim)
        
        scores = self.selector(stack).squeeze(-1) # (TotalBatch,)
        
        # æ•°å€¤å®‰å®šæ€§ã¨æ¢ç´¢ã®ãŸã‚ã®ãƒã‚¤ã‚º
        noise = torch.randn_like(scores) * 0.1
        probs = F.softmax(scores + noise, dim=0)

        # å‹è€…æ±ºå®š
        winner_idx = int(torch.argmax(probs).item())
        winner_name = names[winner_idx]
        winner_content = candidates[winner_idx]

        # çŠ¶æ…‹æ›´æ–° (Exponential Moving Average)
        if winner_content.shape[0] != self.workspace_state.shape[0]:
             if winner_content.shape[0] == 1:
                 winner_content = winner_content.expand_as(self.workspace_state)

        new_state = (1 - self.decay) * winner_content + \
            self.decay * self.workspace_state
        self.workspace_state = new_state.detach()

        return {
            "broadcast": new_state,
            "winner": winner_name,
            "salience": probs.detach()
        }