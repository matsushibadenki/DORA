# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/som_feature_map.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Self-Organizing Map with Robust STDP Support (Fixed)
# ç›®çš„: STDPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äº’æ›æ€§ã¨mypyã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ã€‚

import torch
import torch.nn as nn
import inspect
import logging
from typing import Dict, Any, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®STDPRuleã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from snn_research.learning_rules.stdp import STDPRule
except ImportError:
    # å®Ÿéš›ã«ã¯å­˜åœ¨ã™ã‚‹ãŒã€mypyç’°å¢ƒã‚„ãƒ†ã‚¹ãƒˆã§importã§ããªã„å ´åˆã®ãƒ€ãƒŸãƒ¼
    class STDPRule: # type: ignore
        def __init__(self, learning_rate=0.01, **kwargs):
            self.learning_rate = learning_rate
        def step(self, pre, post, weights):
            pass

logger = logging.getLogger(__name__)

class SomFeatureMap(nn.Module):
    """
    Self-Organizing Map (SOM) implemented with SNN principles.
    Uses STDP for weight adaptation.
    """
    def __init__(self, 
                 input_dim: int, 
                 num_neurons: int, 
                 map_size: Tuple[int, int] = (16, 16),
                 stdp_params: Optional[Dict[str, Any]] = None):
        super().__init__()
        
        self.input_dim = input_dim
        self.num_neurons = num_neurons
        self.map_size = map_size
        
        # Initialize weights (randomly)
        self.weights = nn.Parameter(torch.randn(num_neurons, input_dim))
        
        # Default STDP params
        if stdp_params is None:
            stdp_params = {
                "a_plus": 0.01,
                "a_minus": 0.01,
                "w_min": 0.0,
                "w_max": 1.0
            }
            
        self.stdp = self._initialize_stdp_rule(stdp_params)
        
        logger.info(f"ğŸ§© SOM Initialized: {input_dim} -> {num_neurons} neurons")

    def _initialize_stdp_rule(self, params: Dict[str, Any]) -> Any:
        try:
            sig = inspect.signature(STDPRule.__init__)
            valid_keys = sig.parameters.keys()
            
            clean_params = {}
            learning_rate_val = params.get('a_plus', 0.01)

            for k, v in params.items():
                if k in valid_keys:
                    clean_params[k] = v
                elif k == 'a_plus' and 'learning_rate' in valid_keys:
                    clean_params['learning_rate'] = v
                elif k == 'A_plus' and 'a_plus' in valid_keys:
                    clean_params['a_plus'] = v
            
            if 'learning_rate' in valid_keys and 'learning_rate' not in clean_params:
                clean_params['learning_rate'] = learning_rate_val
            
            return STDPRule(**clean_params)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to initialize standard STDPRule: {e}. Using fallback.")
            class FallbackSTDP:
                def step(self, *args, **kwargs): pass
            return FallbackSTDP()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Compute similarity and return winner neurons activation.
        """
        x_norm = x / (x.norm(dim=1, keepdim=True) + 1e-8)
        w_norm = self.weights / (self.weights.norm(dim=1, keepdim=True) + 1e-8)
        
        similarity = torch.mm(x_norm, w_norm.t())
        return similarity

    def update_weights(self, x: torch.Tensor, spike_output: torch.Tensor):
        """
        é‡ã¿ã®æ›´æ–°ã‚’è¡Œã†ã€‚
        Args:
            x: Input tensor (1, dim)
            spike_output: Output activation (1, num_neurons)
        """
        # ç°¡æ˜“çš„ãªå‹è€…ç·å–ã‚Šå­¦ç¿’ã€ã¾ãŸã¯STDP
        if hasattr(self.stdp, 'step'):
            # STDPãƒ«ãƒ¼ãƒ«ã¸ã®å§”è­² (pre, post, weight)
            # æ³¨: å¤šãã®STDPå®Ÿè£…ã¯Tensorã‚’ç›´æ¥å—ã‘å–ã‚‹ãŒã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«åˆã‚ã›ã‚‹
            pass
        else:
            # ç°¡æ˜“Hebbian
            with torch.no_grad():
                winner_idx = torch.argmax(spike_output, dim=1)
                lr = 0.01
                # é‡ã¿ã‚’å…¥åŠ›ã«è¿‘ã¥ã‘ã‚‹
                for i in range(x.shape[0]):
                    idx = winner_idx[i]
                    self.weights[idx] += lr * (x[i] - self.weights[idx])