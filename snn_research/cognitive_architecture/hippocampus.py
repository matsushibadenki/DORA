# snn_research/cognitive_architecture/hippocampus.py
# Title: Hippocampus v2 (Reinforcement Learning Enabled)
# Description: 
#   è¨˜æ†¶æ§‹é€ ã« 'confidence' (ä¿¡é ¼åº¦) ã‚’è¿½åŠ ã€‚
#   - encode_episode: åˆæœŸä¿¡é ¼åº¦ 1.0 ã§ä¿å­˜ã€‚
#   - update_last_memory: å ±é…¬ä¿¡å·ã«åŸºã¥ã„ã¦ä¿¡é ¼åº¦ã‚’å¢—æ¸›ã•ã›ã‚‹ã€‚
#   - recall: ä¿¡é ¼åº¦ã‚’åŠ å‘³ã—ã¦ã€æ¤œç´¢ã‚¹ã‚³ã‚¢ã‚’èª¿æ•´ã™ã‚‹ã€‚

import json
import torch
import logging
from pathlib import Path
from datetime import datetime
from sentence_transformers import SentenceTransformer, util

class Hippocampus:
    def __init__(self, brain=None, storage_file="dora_memory_bank.json", capacity=200, input_dim=128, device='cpu'):
        self.logger = logging.getLogger("Hippocampus")
        self.storage_path = Path(storage_file)
        
        self.brain = brain
        self.device = brain.device if brain else device
        
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        
        self.memories = self._load_memories()
        self.memory_embeddings = self._precompute_embeddings()
        
        # æœ€å¾Œã«ã‚¢ã‚¯ã‚»ã‚¹/ä½œæˆã—ãŸè¨˜æ†¶ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        self.last_accessed_index = -1
        
        self.logger.info(f"ğŸ§  Hippocampus initialized. Loaded {len(self.memories)} memories.")

    def _load_memories(self):
        if self.storage_path.exists():
            try:
                with open(self.storage_path, 'r', encoding='utf-8') as f:
                    mems = json.load(f)
                    # äº’æ›æ€§: å¤ã„è¨˜æ†¶ã«confidenceãŒãªã„å ´åˆã¯1.0ã‚’è¿½åŠ 
                    for m in mems:
                        if 'confidence' not in m:
                            m['confidence'] = 1.0
                    return mems
            except Exception:
                return []
        return []

    def _save_memories(self):
        with open(self.storage_path, 'w', encoding='utf-8') as f:
            json.dump(self.memories, f, ensure_ascii=False, indent=2)

    def _precompute_embeddings(self):
        if not self.memories:
            return None
        texts = [m['trigger'] for m in self.memories]
        return self.model.encode(texts, convert_to_tensor=True, device='cpu')

    def encode_episode(self, trigger_text, action, intensity):
        # é–¾å€¤ãƒã‚§ãƒƒã‚¯
        if intensity < 15.0:
            return None

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ (åŒã˜ãƒˆãƒªã‚¬ãƒ¼ãªã‚‰æ›´æ–°ã ã‘ã™ã‚‹)
        for i, m in enumerate(self.memories):
            if m['trigger'] == trigger_text:
                # æ—¢å­˜è¨˜æ†¶ã‚’å¼·åŒ–
                self.last_accessed_index = i
                return m

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        memory = {
            "timestamp": timestamp,
            "trigger": trigger_text,
            "action": action,
            "intensity": intensity,
            "confidence": 1.0 # åˆæœŸä¿¡é ¼åº¦
        }
        
        self.memories.append(memory)
        self.last_accessed_index = len(self.memories) - 1
        self._save_memories()
        
        # Update Embeddings
        new_emb = self.model.encode(trigger_text, convert_to_tensor=True, device='cpu')
        if self.memory_embeddings is None:
            self.memory_embeddings = new_emb.unsqueeze(0)
        else:
            self.memory_embeddings = torch.cat([self.memory_embeddings, new_emb.unsqueeze(0)])
            
        print(f"   ğŸ’¾ [Hippocampus] New Memory Formed: '{trigger_text}' (Conf: 1.0)")
        return memory

    def recall(self, current_input):
        if self.memory_embeddings is None:
            return None

        query_emb = self.model.encode(current_input, convert_to_tensor=True, device='cpu')
        scores = util.cos_sim(query_emb, self.memory_embeddings)[0]
        
        best_score_idx = torch.argmax(scores).item()
        best_score = scores[best_score_idx].item()
        
        if best_score > 0.5:
            memory = self.memories[best_score_idx]
            self.last_accessed_index = best_score_idx
            
            # Confidenceã«ã‚ˆã‚‹ãƒ–ãƒ¼ã‚¹ãƒˆåŠ¹æœ
            # ä¿¡é ¼åº¦ãŒé«˜ã„ã»ã©ã€æƒ³èµ·æ™‚ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒå¼·ã„
            boosted_score = best_score * memory['confidence']
            
            print(f"   âš¡ [Hippocampus] Flashback: '{memory['trigger']}' (Conf: {memory['confidence']:.2f})")
            return memory
            
        return None

    def update_last_memory(self, reward_value):
        """
        å ±é…¬ç³»ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åæ˜ ã™ã‚‹ã€‚
        reward_value: +1.0 (Good) or -1.0 (Bad)
        """
        if self.last_accessed_index == -1 or self.last_accessed_index >= len(self.memories):
            return "No recent memory to update."

        memory = self.memories[self.last_accessed_index]
        old_conf = memory['confidence']
        
        # å­¦ç¿’ç‡ 0.2
        new_conf = old_conf + (reward_value * 0.2)
        
        # ç¯„å›²åˆ¶é™ (0.1 ~ 5.0)
        new_conf = max(0.1, min(new_conf, 5.0))
        memory['confidence'] = new_conf
        
        self.memories[self.last_accessed_index] = memory
        self._save_memories()
        
        effect = "STRENGTHENED" if reward_value > 0 else "WEAKENED"
        print(f"   ğŸ§  [Plasticity] Memory '{memory['trigger']}' {effect}. (Conf: {old_conf:.1f} -> {new_conf:.1f})")
        return new_conf