# snn_research/core/snn_core.py
# Title: Spiking Neural Substrate v3.13 (OS Compatible)
# Description: NeuromorphicOSã¨ã®äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼(wake_up, process_stepç­‰)ã‚’è¿½åŠ ã—ã€AttributeErrorã‚’è§£æ¶ˆã€‚

from __future__ import annotations
import logging
import random
import math
from typing import Any, Dict, List, Optional, cast, Union, Tuple

import torch
import torch.nn as nn
from torch import Tensor

from snn_research.hardware.event_driven_simulator import DORAKernel

logger = logging.getLogger(__name__)

class SpikingNeuralSubstrate(nn.Module):
    def __init__(self, config: Dict[str, Any], device: torch.device = torch.device('cpu'), **kwargs: Any) -> None:
        super().__init__()
        self.config = config
        self.device = device
        self.dt: float = config.get("dt", 1.0)
        self.kernel = DORAKernel(dt=self.dt)
        self.group_indices: Dict[str, Tuple[int, int]] = {}
        self.prev_spikes: Dict[str, Optional[Tensor]] = {}
        self.uncertainty_score = 0.0
        
        # [OS Compatibility] State flags
        self.is_awake = False
        self.sleep_cycle_count = 0
        
        # [Compatibility] For users accessing .neuron_groups or .projections directly
        self._projections_registry: Dict[str, Any] = {}
        
        logger.info("âš¡ SpikingNeuralSubstrate v3.13 (OS Compatible) initialized.")

    # --- API Compatibility Layer ---
    @property
    def neuron_groups(self) -> Dict[str, Any]:
        """æ—§APIäº’æ›: ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’Dictã¨ã—ã¦è¿”ã™"""
        return {name: {"range": r, "size": r[1]-r[0]} for name, r in self.group_indices.items()}

    @property
    def projections(self) -> Dict[str, Any]:
        """æ—§APIäº’æ›: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¿”ã™"""
        return self._projections_registry

    def add_neuron_group(self, name: str, count: int, **kwargs: Any) -> None:
        """æ—§APIäº’æ›: _create_groupã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹"""
        v_thresh = kwargs.get("v_thresh", kwargs.get("threshold", 0.5))
        self._create_group(name, count, v_thresh=v_thresh)

    def add_projection(self, name: str, source: str, target: str, **kwargs: Any) -> None:
        """æ—§APIäº’æ›: æŽ¥ç¶šã‚’ä½œæˆã™ã‚‹"""
        if source not in self.group_indices or target not in self.group_indices:
            logger.warning(f"âš ï¸ Cannot connect {source} -> {target}: Group not found.")
            return
        
        src_range = self.group_indices[source]
        tgt_range = self.group_indices[target]
        src_size = src_range[1] - src_range[0]
        tgt_size = tgt_range[1] - tgt_range[0]
        
        # ãƒ©ãƒ³ãƒ€ãƒ é‡ã¿ã§æŽ¥ç¶š
        weight_matrix = torch.randn(src_size, tgt_size).numpy() * 0.1
        self.kernel.connect_groups(src_range, tgt_range, weight_matrix)
        self._projections_registry[name] = {"source": source, "target": target}

    def apply_plasticity_batch(self, firing_rates: Any, phase: str = "neutral") -> None:
        pass

    def get_total_spikes(self) -> int:
        return self.kernel.total_spike_count

    # --- Neuromorphic OS Interface Methods (Added v3.13) ---
    def wake_up(self):
        """OSã‹ã‚‰ã®èµ·å‹•ã‚·ã‚°ãƒŠãƒ«"""
        self.is_awake = True
        self.kernel.is_sleeping = False
        logger.info("ðŸ§  Brain Woke Up (Ready for Processing).")

    def sleep(self):
        """OSã‹ã‚‰ã®åœæ­¢ãƒ»ç¡çœ ã‚·ã‚°ãƒŠãƒ«"""
        self.is_awake = False
        self.kernel.is_sleeping = True
        self.sleep_cycle_count += 1
        self.sleep_process()
        logger.info(f"ðŸ§  Brain Entering Sleep Cycle #{self.sleep_cycle_count}.")

    def process_step(self, task_input: Any) -> Dict[str, Any]:
        """OSã‹ã‚‰ã®ã‚¿ã‚¹ã‚¯å®Ÿè¡Œè¦æ±‚ (forward_stepã¸ã®ãƒ©ãƒƒãƒ‘ãƒ¼)"""
        if isinstance(task_input, dict):
            # å…¥åŠ›ãŒè¾žæ›¸ãªã‚‰ãã®ã¾ã¾æ¸¡ã™ (phaseãªã©ã¯kwargsã¸)
            return self.forward_step(task_input)
        else:
            # æƒ³å®šå¤–ã®å…¥åŠ›å½¢å¼
            return {"error": "Invalid input format"}

    def process_tick(self, dt: float):
        """OSã®ã‚¢ã‚¤ãƒ‰ãƒ«ã‚µã‚¤ã‚¯ãƒ«ä¸­ã«å‘¼ã°ã‚Œã‚‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†"""
        # ç¾åœ¨ã¯ç‰¹ã«ä½•ã‚‚ã—ãªã„ãŒã€æ’å¸¸æ€§ç¶­æŒãªã©ã‚’ã“ã“ã§è¡Œãˆã‚‹
        pass

    def get_brain_status(self) -> Dict[str, Any]:
        """OSã¸çŠ¶æ…‹ã‚’å ±å‘Š"""
        return {
            "is_awake": self.is_awake,
            "uncertainty": self.uncertainty_score,
            "total_spikes": self.get_total_spikes()
        }

    # -------------------------------

    def compile(self, model: Optional[nn.Module] = None) -> None:
        if not model: return
        logger.info(f"ðŸ”¨ Compiling {type(model).__name__}...")
        self.kernel = DORAKernel(dt=self.dt)
        self.group_indices = {}
        
        model_any: Any = model
        
        input_dim = getattr(model_any, 'dim', 128)
        self._create_group("input", input_dim, v_thresh=0.2)
        curr = "input"
        
        if hasattr(model_any, 'layers'):
            for i, layer in enumerate(model_any.layers):
                b_name = f"block_{i}"
                self._create_group(f"{b_name}_in", layer.in_proj.out_features, v_thresh=0.5)
                self.kernel.connect_groups(self.group_indices[curr], self.group_indices[f"{b_name}_in"], layer.in_proj.weight.detach().cpu().numpy())
                
                d_inner = layer.in_proj.out_features // 2
                self._create_group(f"{b_name}_out", layer.out_proj.out_features, v_thresh=0.5)
                src_range = self.group_indices[f"{b_name}_in"]
                self.kernel.connect_groups((src_range[0], src_range[0]+d_inner), self.group_indices[f"{b_name}_out"], layer.out_proj.weight.detach().cpu().numpy())
                
                self.kernel.connect_groups(self.group_indices[curr], self.group_indices[f"{b_name}_out"], torch.eye(layer.out_proj.out_features).numpy())
                curr = f"{b_name}_out"
        
        if hasattr(model_any, "output_projection") and isinstance(model_any.output_projection, nn.Linear):
            self._create_group("output", model_any.output_projection.out_features, v_thresh=0.5)
            self.kernel.connect_groups(self.group_indices[curr], self.group_indices["output"], model_any.output_projection.weight.detach().cpu().numpy())
        else:
            self.group_indices["output"] = self.group_indices[curr]
            
        logger.info(f"âœ… Compilation Successful. Neurons: {len(self.kernel.neurons)}")

    def _create_group(self, name: str, count: int, v_thresh: float):
        start, end = self.kernel.create_layer_neurons(count, layer_id=len(self.group_indices), v_thresh=v_thresh)
        self.group_indices[name] = (start, end)
        self.prev_spikes[name] = torch.zeros(1, count, device=self.device)

    def forward(self, *args, **kwargs) -> Tensor:
        input_tensor = None
        if args:
            for arg in args:
                if isinstance(arg, torch.Tensor):
                    input_tensor = arg
                    break
        if input_tensor is None:
            input_tensor = kwargs.get('input') or kwargs.get('x')
        if input_tensor is None:
            input_tensor = torch.zeros(1, 128, device=self.device)

        res_dict = self.forward_step({"input": input_tensor})
        spikes = res_dict.get("spikes", {})
        
        if "output" in spikes and spikes["output"] is not None:
            out = spikes["output"]
        else:
            valid_keys = [k for k, v in spikes.items() if v is not None]
            if valid_keys:
                out = spikes[valid_keys[-1]]
            else:
                out = torch.zeros(1, 128, device=self.device)
            
        if out.dim() == 1:
            out = out.unsqueeze(0)
        return out

    def forward_step(self, ext_inputs: Dict[str, Tensor], learning: bool = True, dreaming: bool = False, **kwargs: Any) -> Dict[str, Any]:
        # kwargsã‹ã‚‰phaseæƒ…å ±ã‚’å–å¾—ã—ã€dreamingãƒ•ãƒ©ã‚°ã‚„learningãƒ•ãƒ©ã‚°ã‚’èª¿æ•´ã™ã‚‹æ‹¡å¼µã‚‚å¯èƒ½
        phase = kwargs.get("phase", "wake")
        if phase == "dream":
            dreaming = True
        
        jitter = 0.1
        if not dreaming:
            for name, tensor in ext_inputs.items():
                if name in self.group_indices:
                    start_id, _ = self.group_indices[name]
                    t = torch.as_tensor(tensor)
                    indices = torch.nonzero(t.flatten() > 0.1).flatten().cpu().numpy()
                    self.kernel.push_input_spikes([int(idx + start_id) for idx in indices], self.kernel.current_time + jitter)
        else:
            n_len = len(self.kernel.neurons)
            if n_len > 0:
                pop = list(range(n_len))
                sample_size = min(n_len, max(1, n_len // 50))
                dream_indices = random.sample(pop, sample_size)
                self.kernel.push_input_spikes(dream_indices, self.kernel.current_time + jitter)

        counts = self.kernel.run(duration=self.dt, learning_enabled=learning)
        
        curr_spikes = {}
        for name, (s, e) in self.group_indices.items():
            spikes = torch.zeros(1, e-s, device=self.device)
            for nid, count in counts.items():
                if s <= nid < e and count > 0:
                    spikes[0, nid-s] = 1.0
            curr_spikes[name] = spikes
        
        ent = 0.0
        if "output" in curr_spikes:
            ratio = max(1e-9, min(1.0 - 1e-9, float(curr_spikes["output"].mean().item())))
            ent = -(ratio * math.log(ratio) + (1-ratio) * math.log(1-ratio))
        self.uncertainty_score = (ent + self.kernel.stats.get("surprise_index", 0.0)) / 2.0
            
        self.prev_spikes = cast(Dict[str, Optional[Tensor]], curr_spikes)
        return {"spikes": curr_spikes, "uncertainty": self.uncertainty_score}

    def sleep_process(self):
        self.kernel.apply_synaptic_scaling(factor=0.9)
        stats = self.kernel.stats
        tagged = sum(1 for n in self.kernel.neurons for s in n.outgoing_synapses if s.is_tagged)
        logger.info(f"ðŸ§  Plasticity Report: Created={stats['synapses_created']}, Pruned={stats['synapses_pruned']}, Tagged={tagged}, Synapses={stats['current_synapses']}")

    def reset_state(self):
        self.kernel.reset_state()
        self.uncertainty_score = 0.0

SNNCore = SpikingNeuralSubstrate