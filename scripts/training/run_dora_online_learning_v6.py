# scripts/training/run_dora_online_learning_v6.py
# Japanese Title: DORA ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ v14.0 (æ­£è¦åŒ–ãƒã‚¢ã‚½ãƒ³SNN)
# Description: é‡ã¿ã®æ­£è¦åŒ–(Normalization)ã¨å…¥åŠ›ãƒ¬ãƒ¼ãƒˆã®æŠ‘åˆ¶ã«ã‚ˆã‚Šã€éå‰°ç™ºç«ã‚’é˜²ãã€ç‰¹å¾´é¸æŠæ€§ï¼ˆSelectivityï¼‰ã‚’å‘ä¸Šã•ã›ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚

import sys
import os
import logging
import torch
import numpy as np
from torchvision import datasets, transforms
from tqdm import tqdm

sys.path.append(os.getcwd())

from snn_research.core.snn_core import SpikingNeuralSubstrate
from snn_research.core.neuromorphic_os import NeuromorphicOS

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("DORA_Learner_v14_NormPoisson")

# -----------------------------------------------------------------------------
# ãƒã‚¢ã‚½ãƒ³å…¥åŠ›å¯¾å¿œSNNã‚³ã‚¢ (v13ãƒ™ãƒ¼ã‚¹ + è»½é‡åŒ–)
# -----------------------------------------------------------------------------
class PoissonSNN(SpikingNeuralSubstrate):
    def forward_step(self, ext_inputs: dict, learning: bool = True, dreaming: bool = False, **kwargs) -> dict:
        # å‡¦ç†æ™‚é–“ã‚’20msã«çŸ­ç¸®ã—ã¦ã‚¹ãƒ‘ã‚¤ã‚¯æ•°ã‚’æŠ‘ãˆã‚‹
        simulation_duration = kwargs.get("duration", 20.0)
        
        if not dreaming:
            for name, tensor in ext_inputs.items():
                if name in self.group_indices:
                    start_id, _ = self.group_indices[name]
                    input_probs = torch.clamp(tensor.flatten(), 0, 1).cpu().numpy()
                    
                    # é–¾å€¤ã‚’ä¸Šã’ã¦é‡è¦ãªç”»ç´ ã®ã¿ã‚¹ãƒ‘ã‚¤ã‚¯åŒ–
                    active_indices = np.where(input_probs > 0.2)[0]
                    
                    for idx in active_indices:
                        # ãƒ¬ãƒ¼ãƒˆä¿‚æ•°ã‚’ 0.1 -> 0.05 ã«ä¸‹ã’ã¦ç–ã«ã™ã‚‹
                        rate = input_probs[idx] * 0.05 
                        for t in range(int(simulation_duration)):
                            if np.random.random() < rate:
                                self.kernel.push_input_spikes([int(start_id + idx)], self.kernel.current_time + t + 0.1)

        counts = self.kernel.run(duration=simulation_duration, learning_enabled=learning)
        
        curr_spikes = {}
        for name, (s, e) in self.group_indices.items():
            spikes = torch.zeros(1, e-s, device=self.device)
            for nid, count in counts.items():
                if s <= nid < e and count > 0:
                    spikes[0, nid-s] = count 
            curr_spikes[name] = spikes
            
        return {"spikes": curr_spikes}

# -----------------------------------------------------------------------------

class DORAOnlineLearnerV14:
    def __init__(self, n_hidden=1000, device='cpu'):
        self.device = torch.device(device)
        self.n_hidden = n_hidden
        
        self.config = {
            "dt": 1.0, 
            "t_ref": 2.0,
            "tau_m": 20.0,
        }
        self.brain = PoissonSNN(self.config, device=self.device)
        
        # 1. ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å®šç¾©
        self.brain.add_neuron_group("retina", 794, v_thresh=0.5)
        # é–¾å€¤ã‚’å°‘ã—ä¸Šã’ã¦(1.0->2.0)ã€ãƒã‚¤ã‚ºè€æ€§ã‚’ä¸Šã’ã‚‹
        self.brain.add_neuron_group("cortex", n_hidden, v_thresh=2.0)
        
        # 2. æ¥ç¶šæ§‹ç¯‰
        logger.info(f"ğŸ”— Building connections (Hidden={n_hidden})...")
        retina_range = self.brain.group_indices["retina"]
        cortex_range = self.brain.group_indices["cortex"]
        
        n_input = retina_range[1] - retina_range[0]
        n_cortex = cortex_range[1] - cortex_range[0]
        
        # é‡ã¿è¨­å®š: å°‘ã—å¼·ã‚ã«ã—ã¦ãŠãï¼ˆå¾Œã§æ­£è¦åŒ–ã•ã‚Œã‚‹ãŸã‚ï¼‰
        weights = np.random.uniform(0.05, 0.10, (n_cortex, n_input))
        
        # ãƒ©ãƒ™ãƒ«ã¯æ˜ç¢ºã«å¼·ã
        label_start_idx = 784
        weights[:, label_start_idx:] = 2.0 
        
        # æ¥ç¶šå¯†åº¦ (10%)
        mask = (np.random.random(weights.shape) < 0.10).astype(float)
        weights *= mask
        weights[:, label_start_idx:] = 2.0
        
        self.brain.kernel.connect_groups(retina_range, cortex_range, weights)
        
        # å´æŠ‘åˆ¶ (-2.0)
        inhibition_weights = -2.0 * np.ones((n_cortex, n_cortex))
        np.fill_diagonal(inhibition_weights, 0)
        inhib_mask = (np.random.random(inhibition_weights.shape) < 0.20).astype(float)
        inhibition_weights *= inhib_mask
        
        self.brain.kernel.connect_groups(cortex_range, cortex_range, inhibition_weights)
        
        self.brain._projections_registry["optic_nerve"] = {"source": "retina", "target": "cortex"}
        self.brain._projections_registry["lateral_inhibition"] = {"source": "cortex", "target": "cortex"}
        
        self.brain.kernel.structural_plasticity_enabled = False
        
        # 3. OSèµ·å‹•
        self.os_kernel = NeuromorphicOS(self.brain, tick_rate=50)
        self.os_kernel.boot()
        
        logger.info("ğŸ§  Brain Initialized: Normalized Poisson Mode (Duration=20ms).")

    def overlay_label(self, image: torch.Tensor, label: int, use_correct: bool = True) -> torch.Tensor:
        flat_img = torch.clamp(image.view(-1), 0, 1)
        if not use_correct:
            label_candidates = list(range(10))
            if label in label_candidates:
                label_candidates.remove(label)
            label = np.random.choice(label_candidates)
        label_vec = torch.zeros(10)
        label_vec[label] = 1.0 
        return torch.cat([flat_img, label_vec])

    def get_goodness(self, spikes):
        return spikes.sum().item()

    def _safe_numpy(self, tensor_spikes):
        vals = tensor_spikes.detach().cpu().numpy().flatten()
        if vals.size != self.n_hidden:
            safe_vals = np.zeros(self.n_hidden, dtype=np.float32)
            if vals.size > 0:
                limit = min(vals.size, self.n_hidden)
                safe_vals[:limit] = vals[:limit]
            return safe_vals
        return vals

    def normalize_weights(self):
        """ã€æ–°æ©Ÿèƒ½ã€‘é‡ã¿æ­£è¦åŒ–: å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å…¥åŠ›é‡ã¿ã®åˆè¨ˆã‚’ä¸€å®šã«ä¿ã¤"""
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã”ã¨ã®ãƒ«ãƒ¼ãƒ—å‡¦ç†ã¯é‡ã„ãŒã€å­¦ç¿’ã®å®‰å®šæ€§ã«ã¯å¿…é ˆ
        # æœ¬æ¥ã¯è¡Œåˆ—æ¼”ç®—ã§è¡Œã†ã¹ãã ãŒã€ã‚«ãƒ¼ãƒãƒ«æ§‹é€ ä¸Šã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹
        cortex_range = self.brain.group_indices["cortex"]
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ä¸€éƒ¨ã ã‘æ­£è¦åŒ–ã™ã‚‹ã‹ã€æ•°ãƒãƒƒãƒã«ä¸€åº¦å®Ÿè¡Œã™ã‚‹ã®ãŒè‰¯ã„ãŒã€
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆé‡ã„ã‚ˆã†ãªã‚‰é »åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
        target_norm = 1.5 # ç›®æ¨™ã¨ã™ã‚‹é‡ã¿ã®ç·é‡
        
        for i in range(cortex_range[0], cortex_range[1]):
            neuron = self.brain.kernel.neurons[i]
            # ã“ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«å…¥ã£ã¦ãã‚‹ã‚·ãƒŠãƒ—ã‚¹ã‚’æ¢ã™ã®ã¯é€†å‚ç…§ãŒå¿…è¦ã§ã‚«ãƒ¼ãƒãƒ«ãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„å ´åˆãŒã‚ã‚‹
            # DORAã®æ§‹é€ ã§ã¯ã€ŒPre -> Postã€ã®ãƒªã‚¹ãƒˆã—ã‹ãªã„ã®ã§ã€
            # é€†ã«ã€ŒPost -> Preã€ã®æ­£è¦åŒ–ã¯é›£ã—ã„ã€‚
            
            # ä»£æ›¿æ¡ˆï¼šPreå´ã®ã€Œå‡ºåŠ›ã‚·ãƒŠãƒ—ã‚¹ã®å¼·ã•ã€ã‚’åˆ¶é™ã™ã‚‹ï¼ˆãƒªã‚½ãƒ¼ã‚¹é…åˆ†ï¼‰
            # ã“ã“ã§ã¯ run_plasticity å†…ã§ã®æ¸›è¡°(Decay)ã§ä»£ç”¨ã™ã‚‹
            pass

    def run_plasticity(self, pos_spikes, neg_spikes, input_spikes):
        cortex_range = self.brain.group_indices["cortex"]
        retina_range = self.brain.group_indices["retina"]
        
        lr = 0.02
        weight_decay = 0.001 
        
        input_vals = self._safe_numpy(input_spikes)
        pre_indices = np.where(input_vals > 0)[0]
        
        pos_vals = self._safe_numpy(pos_spikes)
        neg_vals = self._safe_numpy(neg_spikes)
        
        updated_count = 0
        active_post_indices = np.where((pos_vals > 0) | (neg_vals > 0))[0]
        
        if len(active_post_indices) == 0:
            return 0

        for pre_idx_rel in pre_indices:
            pre_id = retina_range[0] + pre_idx_rel
            if pre_id >= len(self.brain.kernel.neurons): continue
            
            neuron = self.brain.kernel.neurons[pre_id]
            
            # å…¥åŠ›å¼·åº¦ã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            rate_factor = min(1.0, input_vals[pre_idx_rel] / 3.0)
            
            for synapse in neuron.outgoing_synapses:
                if cortex_range[0] <= synapse.target_id < cortex_range[1]:
                    post_idx = synapse.target_id - cortex_range[0]
                    
                    if post_idx in active_post_indices:
                        val_p = pos_vals[post_idx]
                        val_n = neg_vals[post_idx]
                        
                        # å·®åˆ†å­¦ç¿’ (Difference Learning)
                        diff = val_p - val_n
                        
                        # ä¸æ„Ÿå¸¯: å·®ãŒå°ã•ã„ã¨ãã¯æ›´æ–°ã—ãªã„ï¼ˆãƒã‚¤ã‚ºå¯¾ç­–ï¼‰
                        if abs(diff) < 2.0:
                            continue
                            
                        # Negativeã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’å¼·åŒ– (x2.0)
                        if diff < 0:
                            diff *= 2.0
                            
                        dw = lr * diff * rate_factor
                        
                        synapse.weight += dw
                        
                        # æ˜ç¤ºçš„ãªæ¸›è¡°ï¼ˆNormalizationã®ä»£ã‚ã‚Šï¼‰
                        synapse.weight *= 0.995 
                        
                        # é‡ã¿åˆ¶é™: 0.01 ~ 1.5
                        synapse.weight = max(0.01, min(1.5, synapse.weight))
                        updated_count += 1
        return updated_count

    def predict(self, img):
        best_g = -1
        pred = -1
        scores = []
        
        for l in range(10):
            in_data = self.overlay_label(img, l, True)
            self.brain.reset_state()
            
            res = self.os_kernel.run_cycle({"retina": in_data}, phase="wake")
            g = self.get_goodness(res["spikes"]["cortex"])
            scores.append(g)
            
            if g > best_g:
                best_g = g
                pred = l
        return pred, scores

    def train(self, dataloader, epochs=1):
        self.brain.train()
        
        for epoch in range(epochs):
            correct_train = 0
            total_samples = 0
            
            pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
            
            for img, label in pbar:
                img = img[0]
                lbl = label[0].item()
                
                # --- Positive Phase ---
                in_pos = self.overlay_label(img, lbl, True)
                self.brain.reset_state()
                res_pos = self.brain.forward_step({"retina": in_pos}, learning=True, duration=20.0)
                spikes_pos = res_pos["spikes"]["cortex"]
                input_spikes = res_pos["spikes"]["retina"]
                
                # --- Negative Phase ---
                in_neg = self.overlay_label(img, lbl, False)
                self.brain.reset_state()
                res_neg = self.brain.forward_step({"retina": in_neg}, learning=True, duration=20.0)
                spikes_neg = res_neg["spikes"]["cortex"]

                # --- Learning ---
                self.run_plasticity(spikes_pos, spikes_neg, input_spikes)
                
                pos_g = self.get_goodness(spikes_pos)
                neg_g = self.get_goodness(spikes_neg)
                
                # PositiveãŒæœ‰æ„ã«å¤§ãã‘ã‚Œã°æ­£è§£
                if pos_g > neg_g * 1.1: # 10%ä»¥ä¸Šã®å·®ãŒå¿…è¦
                    correct_train += 1
                
                total_samples += 1
                
                if total_samples % 10 == 0:
                    pbar.set_postfix({
                        "Pos": f"{pos_g:.0f}", 
                        "Neg": f"{neg_g:.0f}", 
                        "Acc": f"{100*correct_train/total_samples:.1f}%"
                    })

    def evaluate(self, dataloader, limit=50):
        correct = 0
        total = 0
        logger.info(f"ğŸ” Evaluating top {limit} samples...")
        
        for i, (img, label) in enumerate(dataloader):
            if i >= limit: break
            img = img[0]
            lbl = label[0].item()
            
            pred, scores = self.predict(img)
            
            # ã‚¹ã‚³ã‚¢åˆ†æ•£ãŒå°ã•ã„å ´åˆã¯è‡ªä¿¡ãªã—(-1)ã¨ã™ã‚‹
            score_std = np.std(scores)
            if score_std < 5.0:
                pred = -1
            
            if pred == lbl: correct += 1
            total += 1
            
            if i < 5:
                print(f"Sample {i}: True={lbl}, Pred={pred}, Scores={np.round(scores, 1)}")
                
        accuracy = 100 * correct / total
        logger.info(f"âœ… Final Test Accuracy: {accuracy:.2f}%")

def main():
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    dataset = datasets.MNIST('./workspace/data', train=True, download=True, transform=transform)
    
    # 500æšã§é«˜é€Ÿã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    train_subset = torch.utils.data.Subset(dataset, range(500))
    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=1, shuffle=True)
    
    test_subset = torch.utils.data.Subset(dataset, range(500, 550))
    test_loader = torch.utils.data.DataLoader(test_subset, batch_size=1, shuffle=False)
    
    learner = DORAOnlineLearnerV14(n_hidden=1000)
    
    logger.info("ğŸš€ Starting DORA Online Learning (v14.0 Normalized Poisson)")
    learner.train(train_loader, epochs=1)
    learner.evaluate(test_loader, limit=50)

if __name__ == "__main__":
    main()