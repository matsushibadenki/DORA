# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: scripts/experiments/brain/run_phase2_mnist_challenge.py
import sys
import os
import time
import logging
import torch
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from typing import Optional, Dict, Any
import numpy as np

# ãƒ‘ã‚¹è§£æ±º
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))

from snn_research.models.visual_cortex import VisualCortex as VisualCortexV2

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Phase2_MNIST")

class MNISTOverlayProcessor:
    """
    ç”»åƒã«ãƒ©ãƒ™ãƒ«æƒ…å ±ã‚’åŸ‹ã‚è¾¼ã‚€ï¼ˆSupervised Forward-Forwardç”¨ï¼‰
    ç”»åƒ(784) + ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆãƒ©ãƒ™ãƒ«(10) = 794æ¬¡å…ƒå…¥åŠ›
    """
    def __init__(self, device):
        self.device = device

    def overlay_label(self, x: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        """
        x: (B, 1, 28, 28) or (B, 784)
        labels: (B,)
        Returns: (B, 794)
        """
        x = x.view(x.size(0), -1).to(self.device)
        labels = labels.to(self.device)

        # ç”»åƒã®æ­£è¦åŒ– (0-1 -> 0.0-1.0)
        x = x / (x.norm(p=2, dim=1, keepdim=True) + 1e-8)

        # ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆãƒ©ãƒ™ãƒ«ã®ç”Ÿæˆ
        one_hot = F.one_hot(labels, num_classes=10).float()
        # ãƒ©ãƒ™ãƒ«ä¿¡å·ã‚’å°‘ã—å¼·ã‚ã«ã™ã‚‹ï¼ˆåˆæœŸå­¦ç¿’ã®ã‚¬ã‚¤ãƒ‰ç”¨ï¼‰
        one_hot = one_hot * 1.5 

        # çµåˆ
        return torch.cat([x, one_hot], dim=1)

def get_mnist_loaders(batch_size=64):
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆã‚’ workspace/data ã«æŒ‡å®š
    data_path = "workspace/data"
    os.makedirs(data_path, exist_ok=True)
    
    train_dataset = datasets.MNIST(data_path, train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST(data_path, train=False, download=True, transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, test_loader

def evaluate(brain, test_loader, processor, device):
    brain.eval() # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒã‚¤ã‚ºãªã—ï¼‰
    correct = 0
    total = 0
    
    logger.info("ğŸ” Evaluating...")
    
    # è©•ä¾¡ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§æœ€åˆã®1000æšã ã‘ãƒã‚§ãƒƒã‚¯
    limit_samples = 1000
    
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(test_loader):
            if total >= limit_samples: break
            
            data = data.to(device)
            target = target.to(device)
            batch_size = data.size(0)
            
            # å„ã‚¯ãƒ©ã‚¹ã®ãƒ©ãƒ™ãƒ«ã‚’åŸ‹ã‚è¾¼ã‚“ã§Goodnessã‚’è¨ˆæ¸¬
            # (Batch, 10, 794) ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œã£ã¦ä¸€æ‹¬å‡¦ç†ã—ãŸã„ãŒã€
            # SNNã®çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆãŒå¿…è¦ãªãŸã‚ã€ã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ«ãƒ¼ãƒ—ã§å›ã™ï¼ˆç²¾åº¦å„ªå…ˆï¼‰
            
            # äºˆæ¸¬ãƒ©ãƒ™ãƒ«æ ¼ç´ç”¨
            batch_goodness = []
            
            for label_idx in range(10):
                brain.reset_state()
                
                # å…¨å“¡ã«åŒã˜ label_idx ã‚’åŸ‹ã‚è¾¼ã‚€
                dummy_labels = torch.full((batch_size,), label_idx, dtype=torch.long, device=device)
                x_in = processor.overlay_label(data, dummy_labels)
                
                # æ¨è«–å®Ÿè¡Œ
                brain(x_in, phase="inference")
                stats = brain.get_goodness()
                
                # å…¨å±¤ã®Goodnessã‚’åˆç®—ã—ã¦ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹
                # ç‰¹ã«æ·±å±¤(V3)ã®åå¿œã‚’é‡è¦–
                score = stats.get("V2_goodness", 0) + stats.get("V3_goodness", 0) * 2.0
                batch_goodness.append(score)
            
            # batch_goodness: List of scalars (ã“ã‚Œã¯ãƒãƒƒãƒå‡¦ç†ã§ãã¦ã„ãªã„ç°¡æ˜“å®Ÿè£…)
            # æ­£ã—ãã¯ãƒãƒƒãƒå†…ã®å€‹ã€…ã®ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã®Goodnessã‚’è¦‹ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
            # SNNã® current implementation ã® get_goodness() ã¯ mean() ã‚’è¿”ã—ã¦ã—ã¾ã†ãŸã‚ã€
            # ãƒãƒƒãƒã‚µã‚¤ã‚º=1 ã§è©•ä¾¡ã™ã‚‹ã‹ã€get_goodnessã‚’æ”¹ä¿®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
            # ä»Šå›ã¯ã€Œãƒãƒƒãƒã‚µã‚¤ã‚º=1ã€ã§æ­£ç¢ºã«è©•ä¾¡ã™ã‚‹å½¢ã«å¤‰æ›´ã™ã‚‹ã€‚
            pass

    # --- ãƒãƒƒãƒã‚µã‚¤ã‚º1ã§ã®æ­£ç¢ºãªè©•ä¾¡ãƒ«ãƒ¼ãƒ— ---
    correct = 0
    total = 0
    
    # ãƒ†ã‚¹ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å†ä½œæˆ (Batch=1)
    test_loader_single = DataLoader(test_loader.dataset, batch_size=1, shuffle=True)
    
    with torch.no_grad():
        for i, (data, target) in enumerate(test_loader_single):
            if i >= 100: break # æ™‚é–“çŸ­ç¸®ã®ãŸã‚100æšã§é€Ÿå ±å€¤ã‚’å‡ºã™
            
            data = data.to(device)
            target = target.item()
            
            best_goodness = -1.0
            predicted_label = -1
            
            for label_c in range(10):
                brain.reset_state()
                
                # å€™è£œãƒ©ãƒ™ãƒ«ã‚’åŸ‹ã‚è¾¼ã‚€
                lbl = torch.tensor([label_c], device=device)
                x_in = processor.overlay_label(data, lbl)
                
                # æ¨è«–
                brain(x_in, phase="inference")
                
                # Goodnesså–å¾— (Batch=1ãªã®ã§ã‚¹ã‚«ãƒ©ãƒ¼ã§OK)
                stats = brain.get_goodness()
                g = stats.get("V2_goodness", 0) + stats.get("V3_goodness", 0)
                
                if g > best_goodness:
                    best_goodness = g
                    predicted_label = label_c
            
            if predicted_label == target:
                correct += 1
            total += 1
            
            if i % 20 == 0:
                print(f".", end="", flush=True)

    print()
    acc = 100.0 * correct / total
    return acc

def run_mnist_challenge():
    logger.info("ğŸ§  Starting Phase 2 MNIST Challenge (Backprop FREE)")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"Device: {device}")
    
    # 1. ã‚³ãƒ³ãƒ•ã‚£ã‚°è¨­å®š
    # å…¥åŠ›æ¬¡å…ƒ = 784(ç”»åƒ) + 10(ãƒ©ãƒ™ãƒ«) = 794
    config = {
        "input_dim": 794, 
        "hidden_dim": 1500, # å®¹é‡ã‚’å°‘ã—å¢—ã‚„ã™
        "num_layers": 3,
        "dt": 1.0,
        "tau_mem": 5.0,
        "learning_rate": 0.08, # å­¦ç¿’ç‡èª¿æ•´
        "ff_threshold": 3.0,
        "noise_level": 1.0
    }
    
    # 2. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    brain = VisualCortexV2(device, config).to(device)
    processor = MNISTOverlayProcessor(device)
    train_loader, test_loader = get_mnist_loaders(batch_size=64)
    
    logger.info(f"Brain Initialized. Input Dim: {config['input_dim']}")
    
    # 3. å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    epochs = 2 # SNNãªã®ã§ã‚¨ãƒãƒƒã‚¯æ•°ã¯å°‘ãªã‚ã§æ§˜å­è¦‹
    
    for epoch in range(1, epochs + 1):
        logger.info(f"Epoch {epoch}/{epochs} Start")
        brain.train()
        
        start_time = time.time()
        batch_count = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data = data.to(device)
            target = target.to(device)
            
            # --- Positive Pass (Wake: æ­£è§£ãƒ©ãƒ™ãƒ«) ---
            brain.reset_state()
            x_pos = processor.overlay_label(data, target)
            brain(x_pos, phase="wake")
            
            # --- Negative Pass (Sleep/Dream: èª¤ã‚Šãƒ©ãƒ™ãƒ«) ---
            brain.reset_state()
            # ãƒ©ãƒ³ãƒ€ãƒ ãªèª¤ã‚Šãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ
            rnd_labels = torch.randint(0, 10, target.shape, device=device)
            # æ­£è§£ã¨åŒã˜ã«ãªã£ã¦ã—ã¾ã£ãŸã‚‚ã®ã¯ +1 ã—ã¦ãšã‚‰ã™
            rnd_labels = torch.where(rnd_labels == target, (rnd_labels + 1) % 10, rnd_labels)
            
            x_neg = processor.overlay_label(data, rnd_labels)
            brain(x_neg, phase="sleep")
            
            batch_count += 1
            if batch_count % 100 == 0:
                metrics = brain.get_stability_metrics()
                v1_rate = metrics.get("V1_firing_rate", 0)
                v3_rate = metrics.get("V3_firing_rate", 0)
                logger.info(f"  Batch {batch_count}: V1 Rate={v1_rate:.1%} V3 Rate={v3_rate:.1%}")

        epoch_time = time.time() - start_time
        logger.info(f"Epoch {epoch} Finished in {epoch_time:.1f}s")
        
        # 4. é€”ä¸­è©•ä¾¡
        acc = evaluate(brain, test_loader, processor, device)
        logger.info(f"ğŸ“Š Epoch {epoch} Test Accuracy: {acc:.2f}%")
        
        # å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯
        if acc < 15.0 and epoch > 1:
            logger.warning("âš ï¸ Accuracy is low. Learning might be unstable.")
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    with open("workspace/reports/mnist_result.txt", "w") as f:
        f.write(f"MNIST Accuracy: {acc}%\n")

if __name__ == "__main__":
    run_mnist_challenge()