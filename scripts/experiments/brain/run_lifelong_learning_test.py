# scripts/experiments/brain/run_lifelong_learning_test.py
# Title: Lifelong Learning Verification (Sleep Effect)
# Description: 
#   Áù°Áú†Ôºà„Ç∑„Éä„Éó„ÇπÂàà„ÇäËæº„ÅøÔºâ„Åå„ÄåÂ£äÊªÖÁöÑÂøòÂç¥„Äç„ÅÆÈò≤Ê≠¢„Å´„Å©„ÅÜÂØÑ‰∏é„Åô„Çã„Åã„ÇíÊ§úË®º„Åô„ÇãÂÆüÈ®ì„ÄÇ
#   Task AÂ≠¶Áøí -> Áù°Áú† -> Task BÂ≠¶Áøí -> Task A„ÅÆË®òÊÜ∂„ÉÜ„Çπ„Éà „Å®„ÅÑ„ÅÜÈ†ÜÂ∫è„ÅßÂÆüË°å„ÄÇ

import sys
import os
import time
import logging
import torch
import numpy as np
from pathlib import Path

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„ÉàË®≠ÂÆö
sys.path.append(str(Path(__file__).resolve().parents[3]))

from app.containers import AppContainer
from snn_research.core.neuromorphic_os import NeuromorphicOS

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', force=True)
logger = logging.getLogger("LifelongExp")

def generate_task_data(device, pattern_id=0, size=10):
    """ÁâπÂÆö„ÅÆ„Éë„Çø„Éº„É≥Ôºà„Çø„Çπ„ÇØÔºâ„ÅÆÂÖ•Âá∫Âäõ„ÇíÁîüÊàê"""
    torch.manual_seed(pattern_id) # „Çø„Çπ„ÇØ„Åî„Å®„Å´Âõ∫ÂÆö„Ç∑„Éº„Éâ
    inputs = torch.randn(size, 128, device=device).abs()
    # „Ç∑„É≥„Éó„É´„Å™„Éû„ÉÉ„Éî„É≥„Ç∞: ÂÖ•Âäõ„ÅÆ‰∏ÄÈÉ®„Å´Âº∑„ÅèÂèçÂøú„Åô„Çã„Çø„Éº„Ç≤„ÉÉ„Éà„Çí‰Ωú„Çã
    targets = (inputs[:, :10].sum(dim=1, keepdim=True) > 5.0).float()
    return inputs, targets

def train_brain(brain, inputs, label, steps=20):
    """Á∞°ÊòìÁöÑ„Å™Â≠¶Áøí„É´„Éº„ÉóÔºàHebbian/STDPÁöÑ„Å™Ê¥ªÊÄßÂåñÔºâ"""
    logger.info(f"üìö Training Task {label}...")
    start_energy = brain.astrocyte.current_energy
    
    for i in range(steps):
        # „Éê„ÉÉ„ÉÅÂá¶ÁêÜÁöÑ„Å´ÂÖ•Âäõ„ÇíÊµÅ„Åô
        for x in inputs:
            brain.process_step(x.unsqueeze(0))
    
    logger.info(f"   -> Finished Task {label}. Energy consumed: {start_energy - brain.astrocyte.current_energy:.1f}")

def test_brain(brain, inputs, label):
    """Ë®òÊÜ∂„ÅÆÂº∑Â∫¶„Çí„ÉÜ„Çπ„ÉàÔºàÂá∫Âäõ„ÅÆÂÆâÂÆöÊÄß„ÇÑÁô∫ÁÅ´Âº∑Â∫¶„ÅßÊ∏¨ÂÆöÔºâ"""
    total_response = 0.0
    with torch.no_grad():
        for x in inputs:
            res = brain.process_step(x.unsqueeze(0))
            out = res.get("output")
            if out is not None:
                total_response += out.mean().item()
    
    avg_resp = total_response / len(inputs)
    logger.info(f"üìù Test Task {label}: Mean Response = {avg_resp:.4f}")
    return avg_resp

def run_experiment():
    print("\n" + "="*60)
    print("üß† DORA Lifelong Learning Experiment: The Sleep Benefit")
    print("="*60 + "\n")

    container = AppContainer()
    config_path = Path("configs/templates/base_config.yaml")
    if not config_path.exists():
        config_path = Path(__file__).resolve().parents[3] / "configs/templates/base_config.yaml"
    
    container.config.from_yaml(str(config_path))
    container.config.training.paradigm.from_value("event_driven")
    container.config.device.from_value("cpu")

    os_kernel = container.neuromorphic_os()
    brain = os_kernel.brain
    device = os_kernel.device
    os_kernel.boot()

    # „Éë„É©„É°„Éº„ÇøË™øÊï¥
    brain.astrocyte.decay_rate = 1.0
    if brain.use_kernel:
        brain.kernel_substrate.kernel.pruning_threshold_sleep = 0.15
        brain.kernel_substrate.kernel.pruning_interval = 50

    # „Éá„Éº„ÇøÁîüÊàê
    task_A_in, _ = generate_task_data(device, pattern_id=100) # Task A
    task_B_in, _ = generate_task_data(device, pattern_id=200) # Task B (A„Å®„ÅØÁï∞„Å™„Çã„Éë„Çø„Éº„É≥)

    # --- Phase 1: Learn Task A ---
    train_brain(brain, task_A_in, "A", steps=5)
    score_A_initial = test_brain(brain, task_A_in, "A (Initial)")
    
    # --- Phase 2: Sleep & Consolidate ---
    print("\nüí§ Sleeping to consolidate Task A...")
    brain.sleep()
    
    # Áù°Áú†‰∏≠„ÅÆÂá¶ÁêÜÔºàScaling & PruningÔºâ
    for _ in range(10):
        # Â§¢ÔºàTask A„ÅÆÂÜçÊ¥ªÊÄßÂåñ„ÇíÊ®°ÂÄ£„Åó„Åü„Éé„Ç§„Ç∫ÂÖ•ÂäõÔºâ
        dream_input = task_A_in[0].unsqueeze(0) + torch.randn_like(task_A_in[0].unsqueeze(0)) * 0.1
        brain.process_step(dream_input)
        if hasattr(brain.kernel_substrate.kernel, "apply_synaptic_scaling"):
             brain.kernel_substrate.kernel.apply_synaptic_scaling(0.98) # Áù°Áú†‰∏≠„ÅÆÊ∏õË°∞
        time.sleep(0.05)
        
    brain.wake_up()
    print("üåÖ Woke up. Brain is refreshed.")

    # --- Phase 3: Learn Task B ---
    # „Åì„Åì„ÅßTask A„ÇíÂøò„Çå„Å¶„Åó„Åæ„ÅÜ„ÅãÔºàÂπ≤Ê∏â„Åô„Çã„ÅãÔºâÔºü
    print("\nüìö Learning new Task B (Interference check)...")
    train_brain(brain, task_B_in, "B", steps=5)
    
    # --- Phase 4: Final Test ---
    print("\nüìä Final Evaluation:")
    score_A_final = test_brain(brain, task_A_in, "A (After Task B)")
    score_B_final = test_brain(brain, task_B_in, "B (New Memory)")
    
    retention_rate = (score_A_final / score_A_initial) * 100 if score_A_initial > 0 else 0
    
    print("-" * 30)
    print(f"   Retention of Task A: {retention_rate:.1f}%")
    print(f"   Acquisition of Task B: {score_B_final:.4f}")
    
    if retention_rate > 80.0:
        print("‚úÖ SUCCESS: Catastrophic Forgetting Mitigated!")
        print("   The brain retained old memories while learning new ones.")
    else:
        print("‚ö†Ô∏è WARNING: Some forgetting occurred.")

if __name__ == "__main__":
    run_experiment()