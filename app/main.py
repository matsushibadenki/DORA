# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: app/main.py
# æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: Neuromorphic OS UI (with Brain Monitor)
# ä¿®æ­£å†…å®¹:
#   - Gradio UIã«ç”»åƒå‡ºåŠ›ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ(brain_monitor)ã‚’è¿½åŠ ã€‚
#   - ChatServiceã‹ã‚‰ã®å¿œç­”ã«å«ã¾ã‚Œã‚‹çµ±è¨ˆæƒ…å ±ã‚’ä½¿ã£ã¦ç”»åƒã‚’æ›´æ–°ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ã€‚

import gradio as gr
import argparse
import logging
import sys
import os
import traceback
import yaml
import numpy as np

from app.containers import AppContainer
# ãƒ—ãƒ­ãƒƒã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from snn_research.visualization.spike_plotter import SpikePlotter

logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def create_ui(container: AppContainer) -> gr.Blocks:
    """Gradio UIã®æ§‹ç¯‰"""
    
    # ã‚µãƒ¼ãƒ“ã‚¹å–å¾— (SNNã‚¨ãƒ³ã‚¸ãƒ³ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ãªãŸã‚ã€containerã‹ã‚‰OSã‚’å–å¾—)
    # ChatServiceçµŒç”±ã§ã¯ãªãã€UIå´ã§æç”»ã™ã‚‹ãŸã‚ã«OSã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚‚å‚ç…§
    brain = container.neuromorphic_os()
    chat_service = container.chat_service()

    with gr.Blocks(title="Neuromorphic OS Dashboard", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ§  Neuromorphic Research OS v1.0")
        
        with gr.Row():
            # å·¦ã‚«ãƒ©ãƒ : ãƒãƒ£ãƒƒãƒˆ
            with gr.Column(scale=1):
                chatbot = gr.Chatbot(label="Consciousness Stream", height=400)
                msg = gr.Textbox(show_label=False, placeholder="Talk to the brain...", scale=4)
                with gr.Row():
                    submit_btn = gr.Button("Send Input", variant="primary")
                    clear_btn = gr.Button("Reset State")

            # å³ã‚«ãƒ©ãƒ : ãƒ¢ãƒ‹ã‚¿ãƒ¼
            with gr.Column(scale=1):
                with gr.Tab("Brain Activity"):
                    # è„³æ´»å‹•ã‚’è¡¨ç¤ºã™ã‚‹ç”»åƒã‚¨ãƒªã‚¢
                    brain_monitor = gr.Image(
                        label="Cortical Activity (V1 | Assoc | Motor)", 
                        type="numpy",
                        interactive=False
                    )
                    stats_box = gr.Markdown("### Status: Waiting for stimuli...")

        # --- ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---

        def user_message(user_input, history):
            if history is None: history = []
            return "", history + [[user_input, None]]

        def bot_response(history):
            if not history: return history, "", None

            user_input = history[-1][0]
            past_history = history[:-1]
            
            # ChatServiceã‹ã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒ å¿œç­”ã‚’å–å¾—
            stream_gen = chat_service.stream_response(user_input, past_history)
            
            try:
                for updated_history, stats in stream_gen:
                    # æœ€æ–°ã®è„³çŠ¶æ…‹ã‚’å–å¾—ã—ã¦ç”»åƒåŒ–
                    # (æœ¬æ¥ã¯stream_genãŒstateã‚‚è¿”ã™ã¹ãã ãŒã€ä»Šå›ã¯OSã‹ã‚‰ç›´æ¥ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¦—ãè¦‹ã‚‹)
                    # â€»ä¸¦åˆ—å‡¦ç†ã§ã¯ãªã„ãŸã‚ã€ã“ã®ç¬é–“ã®çŠ¶æ…‹ã‚’å–å¾—å¯èƒ½
                    
                    # æœ€å¾Œã® forward_step ã§ä¿å­˜ã•ã‚ŒãŸ prev_spikes ã‚’å¯è¦–åŒ–
                    current_state = {"spikes": brain.kernel.prev_spikes}
                    brain_img = SpikePlotter.plot_substrate_state(current_state)
                    
                    # çµ±è¨ˆãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
                    if isinstance(stats, dict):
                        stats_text = f"""
                        **Cycle:** {stats.get('step', 0)}
                        **Total Spikes:** {stats.get('total_spikes', 0)}
                        **Motor Output:** {stats.get('last_motor', '')}
                        """
                    else:
                        stats_text = str(stats)

                    yield updated_history, stats_text, brain_img
                    
            except Exception as e:
                logger.error(f"Error: {e}")
                traceback.print_exc()
                history[-1][1] = f"Error: {str(e)}"
                yield history, "Error", None

        # --- ã‚¤ãƒ™ãƒ³ãƒˆé€£æº ---
        msg.submit(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot_response, [chatbot], [chatbot, stats_box, brain_monitor]
        )
        
        submit_btn.click(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot_response, [chatbot], [chatbot, stats_box, brain_monitor]
        )
        
        clear_btn.click(lambda: [], None, chatbot, queue=False)

    return demo

def main():
    parser = argparse.ArgumentParser(description="Neuromorphic OS Interface")
    parser.add_argument("--config", type=str, default="configs/templates/base_config.yaml", help="Path to config file")
    parser.add_argument("--host", type=str, default="127.0.0.1", help="Server host")
    parser.add_argument("--port", type=int, default=7860, help="Server port")
    args = parser.parse_args()

    container = AppContainer()
    
    if os.path.exists(args.config):
        try:
            with open(args.config, 'r') as f:
                config_data = yaml.safe_load(f)
            container.config.from_dict(config_data)
        except Exception:
            pass
    
    container.wire(modules=[__name__])
    
    try:
        os_system = container.neuromorphic_os()
        os_system.boot()
    except Exception as e:
        logger.critical(f"Boot Failed: {e}")
        return

    logger.info("Constructing UI with Visualization...")
    demo = create_ui(container)
    demo.queue().launch(server_name=args.host, server_port=args.port, share=False)

if __name__ == "__main__":
    main()