# **学習方法の実装状況と選択ガイド**

このドキュメントは、matsushibadenki/dora プロジェクトにおける各種学習アルゴリズムの実装状況を整理し、目的や制約に応じた適切な手法を選択するための指針を示します。

**更新情報 (v8.0 \- 2026-02-09):**

実験的モジュールであった「確率的ヘブ則 (Probabilistic Hebbian)」「因果トレース (Causal Trace)」「物理情報に基づく学習 (Physics Informed)」の3つは、統合自律学習コア **SARA Engine** に機能統合されました。これにより、SARA Engine は物理ダイナミクスと因果関係を自律的に学習する能力を獲得しました。

## **1\. 実装状況一覧表**

現在の実装レベルを以下のステータスで分類しています。

* ✅ **Core**: 中核実装済み。動作確認が取れており、推奨される。  
* ⚠️ **Experimental**: 実験的実装。特定のモデルや条件下でのみ動作、または調整中。  
* ➡️ **Merged**: 他のモジュール（主にSARA Engine）に機能統合され、単体利用は非推奨 (Deprecated)。  
* ❌ **Draft**: 枠組みのみ。

| カテゴリ | 学習手法 | 実装状況 | 主要ファイル (snn\_research/) | 推奨度 |
| :---- | :---- | :---- | :---- | :---- |
| **統合自律学習** | **SARA Engine** | ✅ **Core (v8.0)** | models/experimental/sara\_engine.py | ★★★ (New) |
| **生体模倣** | **STDP** | ✅ Core | learning\_rules/stdp.py | ★★★ |
|  | **Hebbian / BCM** | ✅ Core | learning\_rules/bcm\_rule.py | ★★☆ |
|  | \~\~Probabilistic Hebbian\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
|  | \~\~Causal Trace\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
| **代替BP** | **Forward-Forward** | ⚠️ Experimental | learning\_rules/forward\_forward.py | ★★☆ |
|  | **Predictive Coding** | ⚠️ Experimental | learning\_rules/predictive\_coding\_rule.py | ★★☆ |
| **物理・制御** | **Active Inference** | ⚠️ Experimental | learning\_rules/active\_inference.py | ★★☆ |
|  | \~\~Physics-Informed\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
| **軽量・論理** | **Tsetlin Machine** | ⚠️ Experimental | cognitive\_architecture/tsetlin\_machine.py | ★★☆ |
|  | **HDC** (Hyperdimensional) | ⚠️ Experimental | cognitive\_architecture/hdc\_engine.py | ★☆☆ |
| **高精度(BP)** | **Spikformer** | ✅ Core | models/transformer/spikformer.py | ★★★ |

## **2\. 各手法の詳細と変更点**

### **2.1 SARA Engine (推奨 / 統合コア)**

* **ファイル**: models/experimental/sara\_engine.py  
* **内容**:  
  * **Surprise-Modulated Plasticity**: 予測誤差（驚き）をトリガーとした確率的ヘブ学習（旧 Probabilistic Hebbian の進化版）。  
  * **Recursive Causal Trace**: 再帰的な活動履歴を保持し、時間的な因果関係を学習（旧 Causal Trace の統合）。  
  * **Internal World Model**: 内部シミュレーションにより、環境の物理法則やダイナミクスを獲得（旧 Physics-Informed の統合）。  
* **特徴**: 未知環境での適応、ロボット制御、動的なタスクにおいて最も推奨されるエンジンです。

### **2.2 生体模倣学習 (STDP / BCM)**

* **ステータス**: ✅ Core  
* **ファイル**: learning\_rules/stdp.py, learning\_rules/bcm\_rule.py  
* **内容**: スパイクタイミング依存可塑性およびBienenstock-Cooper-Munro則。  
* **特徴**: 局所的な学習のみで動作するため計算コストが低く、エッジデバイスやニューロモルフィックハードウェアへの移植に最適です。

### **2.3 軽量・論理学習 (Tsetlin / HDC)**

* **ステータス**: ⚠️ Experimental  
* **ファイル**: cognitive\_architecture/tsetlin\_machine.py  
* **内容**: 多数決論理とオートマトンを用いた、乗算を必要としない学習アルゴリズム。  
* **特徴**: 従来のニューラルネットワークと比較して消費電力が圧倒的に少なく、FPGA等への実装に向いています。

### **2.4 統合・廃止された手法 (Deprecated)**

以下の手法は **SARA Engine** に統合されました。個別のファイルは互換性のために残されている場合がありますが、新規開発では SARA Engine を使用してください。

* **Probabilistic Hebbian**: learning\_rules/probabilistic\_hebbian.py → SARAの SurpriseDetector と連携する可塑性へ移行。  
* **Causal Trace**: learning\_rules/causal\_trace.py → SARAの内部バッファ spike\_trace へ移行。  
* **Physics-Informed**: training/trainers/physics\_informed.py → SARAの WorldModel へ移行。

## **3\. 詳細選択ガイド：いつ、どの学習方法を使うべきか**

### **A. 動的な環境での適応・物理インタラクション**

* **推奨**: **SARA Engine**  
* **理由**:  
  * 予測誤差（Surprise）を利用して、報酬が疎な環境でも自律的に学習を進められます。  
  * 内部世界モデルにより、物理的な挙動（慣性や重力の影響など）をシミュレートしながら学習できます。  
* **移行**: 旧 PhysicsInformedTrainer を使用していた箇所は、SARAEngine(config).adapt(...) に置き換えてください。

### **B. リアルタイム・エッジデバイスでの省電力学習**

* **推奨**: **STDP**, **BCM Rule**, **Tsetlin Machine**  
* **理由**: バックプロパゲーションが不要で、局所的な計算のみで完結するため。  
* **選択**: ニューロンベースならSTDP、論理ベースならTsetlin Machineを選択してください。

### **C. 高精度な認識とオフライン定着**

* **推奨**: **Spikformer** (Surrogate Gradient) → **Distillation**  
* **シナリオ**:  
  1. Spikformer (Backprop) で高精度なモデルを作成（教師あり学習）。  
  2. 推論実行中のログを収集。  
  3. 睡眠フェーズ（Distillation）で、短期記憶や高精度モデルの知識を、省電力なSNN（長期記憶）へ蒸留・転送する。

## **4\. サンプルコード: SARA Engine への移行**

旧来の個別モジュール組み合わせから、統合エンジンへの移行例です。

\# \[New Standard\] SARA Engine を使用した学習ループ  
from snn\_research.models.experimental.sara\_engine import SARAEngine  
from snn\_research.config.schema import SARAConfig

\# 1\. 統合設定 (旧モジュールの機能はここでパラメータとして指定)  
config \= SARAConfig(  
    hidden\_size=128,  
    plasticity\_mode="surprise\_modulated", \# 旧 ProbabilisticHebbian  
    reasoning\_depth=3,                    \# 旧 CausalTrace  
    use\_world\_model=True                  \# 旧 PhysicsInformed  
)

\# 2\. エンジン初期化  
brain \= SARAEngine(config)

\# 3\. 自律学習ステップ (推論 \-\> 予測誤差計算 \-\> 可塑性更新)  
\# targets がない場合は自己教師あり学習として動作  
results \= brain.adapt(inputs=sensory\_data, targets=None)

print(f"Surprise Level: {results\['surprise'\].mean():.4f}")  
