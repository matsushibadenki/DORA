# **学習方法の実装状況と選択ガイド**

このドキュメントは、matsushibadenki/dora プロジェクトにおける各種学習アルゴリズムの実装状況を整理し、目的や制約に応じた適切な手法を選択するための指針を示します。

**更新情報 (v9.0 \- 2026-02-09):**

統合自律学習コア **SARA Engine** が v9.0 へアップデートされました。

これに伴い、以下の手法が SARA Engine に完全統合され、単独モジュールとしては非推奨（Deprecated/Merged）となりました。

* **Predictive Coding (予測符号化)**: 階層的な予測誤差の伝播と推論。  
* **Active Inference (能動的推論)**: 自由エネルギー最小化による行動生成。  
* **Probabilistic Hebbian**: 驚き（Surprise）駆動型の可塑性。  
* **Causal Trace**: 時間的因果関係の保持。  
* **Physics-Informed**: 内部世界モデルによる物理則の獲得。

## **1\. 実装状況一覧表**

現在の実装レベルを以下のステータスで分類しています。

* ✅ **Core**: 中核実装済み。動作確認が取れており、推奨される。  
* ⚠️ **Experimental**: 実験的実装。特定のモデルや条件下でのみ動作、または調整中。  
* ➡️ **Merged**: **SARA Engine** に機能統合され、単体利用は非推奨 (Deprecated)。  
* ❌ **Draft**: 枠組みのみ。

| 学習方法 | ステータス | 推奨用途 | 実装モジュール | 備考 |
| :--- | :--- | :--- | :--- | :--- |
| **STDP (Spike-Timing-Dependent Plasticity)** | ✅ Stable | 生物学的シミュレーション, 局所特徴抽出 | `snn_research.learning_rules.stdp` | 基本的な教師なし学習。 |
| **R-STDP (Reward-Modulated STDP)** | ✅ Stable | 強化学習タスク, 運動制御 | `snn_research.learning_rules.reward_modulated_stdp` | 報酬信号による変調を加えたもの。 |
| **Surrogate Gradient (Backprop)** | ✅ Stable | 教師あり学習, 高精度タスク (MNIST/CIFAR) | `spikingjelly`, `snn_research.training.trainers` | 従来のDLフレームワークと親和性が高い。 |
| **Predictive Coding (Classic)** | ⚠️ Deprecated | (SARA Engineへ移行) | `snn_research.models.experimental.predictive_coding_model` | 単体の予測符号化モデルはSARAへ統合されました。 |
| **Active Inference** | ⚠️ Deprecated | (SARA Engineへ移行) | `snn_research.adaptive.active_inference_agent` | 単体の能動的推論エージェントはSARAへ統合されました。 |
| **SARA Engine (Integrated)** | 🚀 **Recommended** | **自律学習, 汎用知能エージェント** | `snn_research.models.experimental.sara_engine` | 予測符号化・能動的推論・物理制約を統合した次世代コア。 |
| **Concept Augmented Learning** | 🧪 Experimental | 概念形成, マルチモーダル学習 | `snn_research.training.trainers.concept_augmented_trainer` | 言語概念と感覚入力を結びつける学習。 |
| **Physics-Informed Learning** | 🧪 Experimental | 物理シミュレーション, ロボティクス | `snn_research.training.trainers.physics_informed` | 物理法則の整合性を損失関数に組み込む。 |

---

## 選択ガイド

### ケース1: とにかく高い認識精度を出したい (画像認識など)
* **推奨:** **Surrogate Gradient (Backpropagation)**
* **理由:** 既存のディープラーニングの資産を最大限活かせます。`spikingjelly` ベースのトレーナーを使用してください。

### ケース2: ロボット制御や環境相互作用を学習させたい
* **推奨:** **SARA Engine (v10.0)**
* **理由:** 外部環境のモデル化（世界モデル）と、それに基づく行動生成（能動的推論）が統合されています。エネルギー効率と適応性に優れます。以前の R-STDP よりも目的指向の行動が可能です。

### ケース3: 生物学的な脳の学習メカニズムを研究したい
* **推奨:** **STDP / R-STDP**
* **理由:** 局所的なシナプス可塑性のみを用いた自己組織化の観察に適しています。

### ケース4: 未知の環境で自律的に概念を獲得させたい
* **推奨:** **SARA Engine + Concept Augmented**
* **理由:** SARAエンジンの予測誤差最小化プロセスに加え、Concept Augmented Trainerの概念マッピングを組み合わせることで、センサー入力から抽象的な意味表現を獲得できます。

## SARA Engine について

**SARA (Self-Adaptive Robotic Architecture) Engine** は、本プロジェクトの最重要実験モジュールです。以下の機能を単一の `nn.Module` 内で統合しています。

1.  **Hierarchical Predictive Coding**: 入力を予測し、予測誤差のみを上位層へ伝播させます。
2.  **Active Inference**: 予測誤差（自由エネルギー）を最小化するように、内部状態の更新だけでなく「行動」を出力します。
3.  **Homeostatic Regulation**: 「感情」や「エネルギー」といった内部変数を持ち、学習率や活動レベルを動的に調整します。
4.  **Physics-Informed Consistency**: 内部表現が物理法則（慣性や保存則）に反しないよう制約をかけ、ロバストな推論を行います。

実験的なタスク（迷路探索、アーム制御、未知物体認識）を行う場合は、まず **SARA Engine** の使用を検討してください。


  
  
## **2\. 各手法の詳細と変更点**

### **2.1 SARA Engine (推奨 / 統合コア)**

* **ファイル**: models/experimental/sara\_engine.py  
* **概要**: 脳の主要な学習・推論メカニズムを単一のアーキテクチャに統合したエンジンです。  
* **統合された機能**:  
  1. **Predictive Coding**: 内部世界モデル（Top-down）と感覚入力（Bottom-up）の誤差を計算し、推論を駆動します。  
  2. **Active Inference**: 期待自由エネルギー（EFE）を最小化するように、環境への「行動」を出力します。  
  3. **Surprise-Modulated Plasticity**: 予測誤差（驚き）が大きい時ほど、シナプス可塑性（学習率）を高めます。  
  4. **Internal World Model**: 環境の物理法則や因果関係をニューラルネットワークの重みとして保持・シミュレートします。

### **2.2 生体模倣学習 (STDP / BCM)**

* **ステータス**: ✅ Core  
* **ファイル**: learning\_rules/stdp.py, learning\_rules/bcm\_rule.py  
* **特徴**: 局所的な学習のみで動作するため計算コストが低く、エッジデバイスやニューロモルフィックハードウェアへの移植に最適です。

### **2.3 軽量・論理学習 (Tsetlin / HDC)**

* **ステータス**: ⚠️ Experimental  
* **ファイル**: cognitive\_architecture/tsetlin\_machine.py, hdc\_engine.py  
* **特徴**:  
  * **Tsetlin Machine**: 命題論理とオートマトンを用いた学習。浮動小数点演算（乗算）を行わず、ビット演算のみで高速・省電力に動作します。  
  * **HDC**: 情報を超高次元ベクトルとして分散表現し、ロバストな連想記憶を実現します。

### **2.4 Forward-Forward Algorithm**

* **ステータス**: ⚠️ Experimental  
* **ファイル**: learning\_rules/forward\_forward.py  
* **特徴**: バックプロパゲーションを使わず、Positiveデータ（正解）とNegativeデータ（偽物）をパスさせることで層ごとに局所的に学習します。GPUメモリ効率が良いのが特徴です。

## **3\. 詳細選択ガイド：いつ、どの学習方法を使うべきか**

### **A. 未知の環境での自律エージェント・ロボット**

* **推奨**: **SARA Engine (v9.0)**  
* **理由**:  
  * 「世界モデル」で未来を予測し、「能動的推論」でゴールに向かう行動を生成できるため。  
  * 報酬が与えられない状況でも、予測誤差（Surprise）を減らす動機だけで学習が進むため。  
* **コード例**:  
  brain \= SARAEngine(config)  
  \# 推論・学習・行動生成を一括実行  
  action, memory, info \= brain.adapt(sensory\_input, target\_goal=desired\_state)

### **B. 超低消費電力・FPGA/ASIC実装**

* **推奨**: **Tsetlin Machine** または **STDP**  
* **理由**:  
  * **Tsetlin**: 論理演算のみで推論・学習が可能。  
  * **STDP**: スパイクのタイミングのみで重みを更新でき、複雑な制御回路が不要。

### **C. 固定データセットでの高精度認識（画像・音声）**

* **推奨**: **Spikformer** (Surrogate Gradient)  
* **理由**: Transformerアーキテクチャによる大域的な特徴抽出と、教師あり学習による強力な最適化が可能なため。

## **4\. 今後のロードマップ**

* **Phase 3 (完了)**: SARA Engine v9.0 への主要アルゴリズム（Predictive Coding, Active Inference）の完全統合。  
* **Phase 4 (次)**:  
  * **Multi-Agent SARA**: 複数のSARAエンジン間での言語・文化の創発（Naming Game等）。  
  * **Hardware Acceleration**: Tsetlin Machine や SARA の軽量版をRustカーネル経由で高速化。