# **学習方法の実装状況と選択ガイド**

このドキュメントは、matsushibadenki/dora プロジェクトにおける各種学習アルゴリズムの実装状況を整理し、目的や制約に応じた適切な手法を選択するための指針を示します。

**更新情報 (v9.0 \- 2026-02-09):**

統合自律学習コア **SARA Engine** が v9.0 へアップデートされました。

これに伴い、以下の手法が SARA Engine に完全統合され、単独モジュールとしては非推奨（Deprecated/Merged）となりました。

* **Predictive Coding (予測符号化)**: 階層的な予測誤差の伝播と推論。  
* **Active Inference (能動的推論)**: 自由エネルギー最小化による行動生成。  
* **Probabilistic Hebbian**: 驚き（Surprise）駆動型の可塑性。  
* **Causal Trace**: 時間的因果関係の保持。  
* **Physics-Informed**: 内部世界モデルによる物理則の獲得。

## **1\. 実装状況一覧表**

現在の実装レベルを以下のステータスで分類しています。

* ✅ **Core**: 中核実装済み。動作確認が取れており、推奨される。  
* ⚠️ **Experimental**: 実験的実装。特定のモデルや条件下でのみ動作、または調整中。  
* ➡️ **Merged**: **SARA Engine** に機能統合され、単体利用は非推奨 (Deprecated)。  
* ❌ **Draft**: 枠組みのみ。

| カテゴリ | 学習手法 | 実装状況 | 主要ファイル (snn\_research/) | 推奨度 |
| :---- | :---- | :---- | :---- | :---- |
| **統合自律学習** | **SARA Engine** | ✅ **Core (v9.0)** | models/experimental/sara\_engine.py | ★★★ (New) |
| **推論・制御** | \~\~Active Inference\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
|  | \~\~Predictive Coding\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
|  | \~\~Physics-Informed\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
| **生体模倣** | **STDP** | ✅ Core | learning\_rules/stdp.py | ★★★ |
|  | **Hebbian / BCM** | ✅ Core | learning\_rules/bcm\_rule.py | ★★☆ |
|  | \~\~Probabilistic Hebbian\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
|  | \~\~Causal Trace\~\~ | ➡️ **Merged** | (SARA Engineに統合) | \- |
| **代替BP** | **Forward-Forward** | ⚠️ Experimental | learning\_rules/forward\_forward.py | ★★☆ |
| **軽量・論理** | **Tsetlin Machine** | ⚠️ Experimental | cognitive\_architecture/tsetlin\_machine.py | ★★☆ |
|  | **HDC** (Hyperdimensional) | ⚠️ Experimental | cognitive\_architecture/hdc\_engine.py | ★☆☆ |
| **高精度(BP)** | **Spikformer** | ✅ Core | models/transformer/spikformer.py | ★★★ |

## **2\. 各手法の詳細と変更点**

### **2.1 SARA Engine (推奨 / 統合コア)**

* **ファイル**: models/experimental/sara\_engine.py  
* **概要**: 脳の主要な学習・推論メカニズムを単一のアーキテクチャに統合したエンジンです。  
* **統合された機能**:  
  1. **Predictive Coding**: 内部世界モデル（Top-down）と感覚入力（Bottom-up）の誤差を計算し、推論を駆動します。  
  2. **Active Inference**: 期待自由エネルギー（EFE）を最小化するように、環境への「行動」を出力します。  
  3. **Surprise-Modulated Plasticity**: 予測誤差（驚き）が大きい時ほど、シナプス可塑性（学習率）を高めます。  
  4. **Internal World Model**: 環境の物理法則や因果関係をニューラルネットワークの重みとして保持・シミュレートします。

### **2.2 生体模倣学習 (STDP / BCM)**

* **ステータス**: ✅ Core  
* **ファイル**: learning\_rules/stdp.py, learning\_rules/bcm\_rule.py  
* **特徴**: 局所的な学習のみで動作するため計算コストが低く、エッジデバイスやニューロモルフィックハードウェアへの移植に最適です。

### **2.3 軽量・論理学習 (Tsetlin / HDC)**

* **ステータス**: ⚠️ Experimental  
* **ファイル**: cognitive\_architecture/tsetlin\_machine.py, hdc\_engine.py  
* **特徴**:  
  * **Tsetlin Machine**: 命題論理とオートマトンを用いた学習。浮動小数点演算（乗算）を行わず、ビット演算のみで高速・省電力に動作します。  
  * **HDC**: 情報を超高次元ベクトルとして分散表現し、ロバストな連想記憶を実現します。

### **2.4 Forward-Forward Algorithm**

* **ステータス**: ⚠️ Experimental  
* **ファイル**: learning\_rules/forward\_forward.py  
* **特徴**: バックプロパゲーションを使わず、Positiveデータ（正解）とNegativeデータ（偽物）をパスさせることで層ごとに局所的に学習します。GPUメモリ効率が良いのが特徴です。

## **3\. 詳細選択ガイド：いつ、どの学習方法を使うべきか**

### **A. 未知の環境での自律エージェント・ロボット**

* **推奨**: **SARA Engine (v9.0)**  
* **理由**:  
  * 「世界モデル」で未来を予測し、「能動的推論」でゴールに向かう行動を生成できるため。  
  * 報酬が与えられない状況でも、予測誤差（Surprise）を減らす動機だけで学習が進むため。  
* **コード例**:  
  brain \= SARAEngine(config)  
  \# 推論・学習・行動生成を一括実行  
  action, memory, info \= brain.adapt(sensory\_input, target\_goal=desired\_state)

### **B. 超低消費電力・FPGA/ASIC実装**

* **推奨**: **Tsetlin Machine** または **STDP**  
* **理由**:  
  * **Tsetlin**: 論理演算のみで推論・学習が可能。  
  * **STDP**: スパイクのタイミングのみで重みを更新でき、複雑な制御回路が不要。

### **C. 固定データセットでの高精度認識（画像・音声）**

* **推奨**: **Spikformer** (Surrogate Gradient)  
* **理由**: Transformerアーキテクチャによる大域的な特徴抽出と、教師あり学習による強力な最適化が可能なため。

## **4\. 今後のロードマップ**

* **Phase 3 (完了)**: SARA Engine v9.0 への主要アルゴリズム（Predictive Coding, Active Inference）の完全統合。  
* **Phase 4 (次)**:  
  * **Multi-Agent SARA**: 複数のSARAエンジン間での言語・文化の創発（Naming Game等）。  
  * **Hardware Acceleration**: Tsetlin Machine や SARA の軽量版をRustカーネル経由で高速化。