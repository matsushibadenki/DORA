# 🎯 DORA─Neuromorphic Research OS - Unified Objectives (v2.2)─

---

## 📌 Most Important Constraints (Non-Negotiable)

本プロジェクトでは、以下を**絶対制約（設計上の禁止事項）**とする。

- ❌ **誤差逆伝播法（Backpropagation）を使用しない**
- ❌ **行列演算（Dense / GEMM / Attention行列）を前提としない**
- ❌ **GPU依存の計算モデルにしない**

> これらは「最適化の選択肢」ではなく  
> **生物学的妥当性・ハードウェア適合性を守るための原理制約**である。

---

## 📌 Mission Statement

本プロジェクトの目的は、

**人間の脳が持つ**
- 高いエネルギー効率
- 局所的可塑性
- 時間依存ダイナミクス
- 自律的な学習・安定化

を計算原理として再構成し、

> **SNN（Spiking Neural Network）を中核とした  
> Neuromorphic Research OS を構築すること**

である。

### 本プロジェクトが目指すもの
- ANNを「模倣・変換」することではない
- AGI完成を宣言することではない
- **脳型計算の実験・観測・比較を可能にする基盤**を作ること

### 達成目標（実務的定義）
- **精度・効率・速度の複合指標でANNを上回るSNN構成を実証**
- **継続学習が可能で、破壊的忘却を起こさない**
- **コンシューマーハードウェア上で動作する**

**Current Status:**  
✅ Phase 1 完了  
🚧 Phase 2 進行中（学習安定性が最大課題）

---

## 🛠️ Coding Rules (v1.1)

1. **ファイル管理**
   - `workspace/` 以外にキャッシュ・データ・モデルを生成しない
2. **ディレクトリ整合性**
   - 新規ファイルは既存構造の意味論を壊さない
3. **計算原則**
   - 明示的な時間ステップを持たない処理は禁止
   - 行列積を暗黙に含むAPI使用は禁止

---

## 📊 Phase 1: Core System Validation（完了）

### Phase 1の位置づけ
Phase 1 は「性能競争」ではなく、

> **T=1ネイティブSNNが  
> 実用的な速度・消費電力で動作することの検証**

を目的とした。

### 達成指標

| 指標 | 目標 | 達成値 | 評価 |
|----|----|----|----|
| 推論レイテンシ | < 10ms | **3.02ms** | ✅ |
| 消費電力 | ANN比 1/50 | 1/20〜1/100 | ✅ |
| 学習安定性 | ≥ 95% | **81.25%** | ⚠️ |

---

## 🚀 Phase 2: Beyond ANN (進行中)

### Phase 2の再定義（重要）

Phase 2 の目的は  
**「ANNを超えること」そのものではない**。

> **ANNと同等以上の精度を  
> ANNでは不可能な制約条件下で達成すること**

が本質である。

---

## 🎯 Phase 2 – Three Axes of Evaluation

### Axis 1: Accuracy Parity (Native SNN Only)

- **CIFAR-10**: ≥ 97.5%（T=1・ネイティブ学習）
- **CIFAR-100**: ≥ 82%
- **ImageNet Top-1**: ≥ 75%

※ ANN→SNN変換手法は**比較対象**であり、  
　本プロジェクトの達成条件には含めない。

---

### Axis 2: Efficiency Dominance

| 指標 | 目標 |
|----|----|
| エネルギー効率 | ANN比 **1/100**（同精度） |
| 推論レイテンシ | < 5ms |
| 反射的応答 | < 1ms |
| 発火率 | < 5% active neurons |
| メモリ使用量 | ANN比 1/10 |

---

### Axis 3: Capability Extension (ANNが苦手な領域)

- 継続学習（破壊的忘却なし）
- Few-shot 学習（10サンプルで90%）
- 不確実性推定（メタ認知）
- 計算量の自律的調整（System 1 / 2 切替）

---

## 🧠 Learning Principles (最重要設計原理)

以下は**第一級学習機構**とする：

- **STDP / R-STDP**
- **Forward-Forward**
- **Active Inference**
- **局所誤差信号・蒸留**

以下は**補助的役割**に限定する：

- Surrogate Gradient（安定化用途）
- ANN / LLM（教師・比較・解析用）

---

## 🔬 Phase 2 最大のボトルネック

| 項目 | 状態 | 優先度 |
|----|----|----|
| 学習安定性 | 81.25% | 🔴 最優先 |
| 再現性 | 不十分 | 🔴 |
| 精度 | ほぼ到達 | 🟡 |
| 効率 | 達成済 | 🟢 |

**結論**:  
Phase 2 は「新機能追加」ではなく  
**学習則と時間ダイナミクスの徹底的な安定化フェーズ**である。

---

## 🧪 Success Criteria (Phase 2 完了条件)

以下 **すべて** を満たした時点で Phase 2 完了とする。

1. **精度**
   - CIFAR-10 ≥ 97.5%
   - ImageNet Top-1 ≥ 75%
   - 学習成功率 ≥ 95%

2. **効率**
   - ANN比エネルギー 1/100
   - 推論 < 5ms
   - 発火率 < 5%

3. **能力**
   - 継続学習（50タスク・精度低下 < 5%）
   - Few-shot（10サンプルで90%）
   - 不確実性推定 90%

---

## 📜 Conclusion

このプロジェクトは、

- 「AGIを作った」と主張するためのものではない
- 「既存ANNを置き換える」ためだけのものでもない

**脳型計算が成立する条件と限界を、  
実装と実験を通して明らかにする研究基盤**である。

成功とは、
> **制約を守ったまま、  
> それでもANNに勝てることを示すこと**

である。

---

## 🧭 Implementation Priority Order

迷った場合、以下の順序を厳守する：

1. **学習安定性**
2. **時間表現の正確さ**
3. **局所可塑性**
4. 精度
5. エネルギー効率
6. スパース性
7. 自律性・社会性

> Phase 2 における最大の敵は  
> 「精度不足」ではなく  
> **不安定な学習である**。
